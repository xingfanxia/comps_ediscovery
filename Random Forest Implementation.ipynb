{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"#What-is-Random-Forest\" data-toc-modified-id=\"What-is-Random-Forest-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>What is Random Forest</a></span></li><li><span><a href=\"#The-algorithm\" data-toc-modified-id=\"The-algorithm-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The algorithm</a></span></li><li><span><a href=\"#Data-Prep\" data-toc-modified-id=\"Data-Prep-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Prep</a></span></li><li><span><a href=\"#Decision-Tree-and-Random-Forest\" data-toc-modified-id=\"Decision-Tree-and-Random-Forest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Decision Tree and Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-tree-basics\" data-toc-modified-id=\"Decision-tree-basics-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Decision tree basics</a></span></li><li><span><a href=\"#Implementation-of-Tree\" data-toc-modified-id=\"Implementation-of-Tree-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Implementation of Tree</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Decision trees can suffer from high variance which makes their results fragile to the specific training data used.\n",
    "\n",
    ">Building multiple models from samples of your training data, called bagging, can reduce this variance, but the trees are highly correlated.\n",
    "\n",
    ">Random Forest is an extension of bagging that in addition to building trees based on multiple samples of your training data, it also constrains the features that can be used to build the trees, forcing trees to be different. This, in turn, can give a lift in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Decision trees involve the greedy selection of the best split point from the dataset at each step.\n",
    "\n",
    ">This algorithm makes decision trees susceptible to high variance if they are not pruned. This high variance can be harnessed and reduced by creating multiple trees with different samples of the training dataset (different views of the problem) and combining their predictions. This approach is called bootstrap aggregation or bagging for short.\n",
    "\n",
    ">A limitation of bagging is that the same greedy algorithm is used to create each tree, meaning that it is likely that the same or very similar split points will be chosen in each tree making the different trees very similar (trees will be correlated). This, in turn, makes their predictions similar, mitigating the variance originally sought.\n",
    "\n",
    ">We can force the decision trees to be different by limiting the features (rows) that the greedy algorithm can evaluate at each split point when creating the tree. This is called the Random Forest algorithm.\n",
    "\n",
    ">Like bagging, multiple samples of the training dataset are taken and a different tree trained on each. The difference is that at each point a split is made in the data and added to the tree, only a fixed subset of attributes can be considered.\n",
    "\n",
    ">For classification problems,  the number of attributes to be considered for the split is limited to the square root of the number of input features.\n",
    "\n",
    ">The result of this one small change are trees that are more different from each other (uncorrelated) resulting predictions that are more diverse and a combined prediction that often has better performance that single tree or bagging alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample data used is the sonar dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:02:47.502773Z",
     "start_time": "2017-10-17T17:02:47.386017Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p data/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:04:34.712910Z",
     "start_time": "2017-10-17T17:04:34.673041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/research/sonar.all-data.csv', <http.client.HTTPMessage at 0x108f47128>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request as request\n",
    "file_path = 'data/research/sonar.all-data.csv'\n",
    "d_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
    "request.urlretrieve(d_url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:05:25.220917Z",
     "start_time": "2017-10-17T17:05:24.662241Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:05:25.824825Z",
     "start_time": "2017-10-17T17:05:25.814453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a decision tree, split points are chosed by finding the feature and the value of that feature which results in lowerst cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problem, this cost is usually evaluated by a cost function called Gini index. Gini index calculates the purity of the group of data created by the split point.\n",
    "\n",
    "A tree node is pure (`gini = 0`) if all instances it applies to belong to the same class.\n",
    "\n",
    "*Gini Impurity* is measured as \n",
    "$$\n",
    "G_i = 1 - \\sum_{k=1}^n p_{i,k}^2\n",
    "$$\n",
    "\n",
    "where $p_{i,k}$ refers to the ratio of class $k$  instances among the whole input instances in the $i^{th}$ node.\n",
    "\n",
    "For example, assume there is a node with 54 input instances, 0 of them belong to class A, 49 of them belong to class B, and 5 of them belong to class C. Then the gini score is $1 - (0/54)^2 - (49/54)^2 - (5/54)^2 \\approx 0.168$\n",
    "\n",
    "In our case, we only want a binary classifier outputing `relevant (1)` or `irrelavent (0)`. So if a node perfectly separated the input into one class(leaf), the *gini impurity* will be 0.\n",
    "\n",
    "Another measure will be *Entropy*:\n",
    "$$H_i = - \\sum_{k=1 \\mid p_{i,k} \\neq 0}^n p_{i,k}log(p_{i,k})$$\n",
    "Note *Entropy* is more expensive as it uses $log$.\n",
    "\n",
    "> - Gini is intended for continuous attributes, and Entropy for attributes that occur in classes\n",
    "- Gini is to minimize misclassification\n",
    "- Entropy is for exploratory analysis\n",
    "- Entropy may be a little slower to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T16:24:46.529728Z",
     "start_time": "2017-10-12T16:24:46.515712Z"
    }
   },
   "source": [
    "General Implementation of both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:05:38.380220Z",
     "start_time": "2017-10-17T17:05:38.365889Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_shannon_entropy(self, left, right):\n",
    "        left_sum = sum(left.values())\n",
    "        right_sum = sum(right.values())\n",
    "        if 0 in left.values():\n",
    "            left_entropy = 0\n",
    "        else:\n",
    "            left_entropy = sum([-(i/left_sum)*np.log2(i/left_sum) for i in left.values()])\n",
    "\n",
    "        if 0 in right.values():\n",
    "            right_entropy = 0\n",
    "        else:\n",
    "            right_entropy = sum([-(i/right_sum)*np.log2(i/right_sum) for i in right.values()])\n",
    "        entropy = (left_entropy*left_sum + right_entropy*right_sum) / (left_sum + right_sum)\n",
    "        return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:05:38.658171Z",
     "start_time": "2017-10-17T17:05:38.654286Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_gini_index(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:05:38.953897Z",
     "start_time": "2017-10-17T17:05:38.951196Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0368\n",
      "         0       1       2       3       4       5       6       7       8   \\\n",
      "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "5    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
      "6    0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
      "7    0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
      "8    0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
      "9    0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
      "10   0.0039  0.0063  0.0152  0.0336  0.0310  0.0284  0.0396  0.0272  0.0323   \n",
      "11   0.0123  0.0309  0.0169  0.0313  0.0358  0.0102  0.0182  0.0579  0.1122   \n",
      "12   0.0079  0.0086  0.0055  0.0250  0.0344  0.0546  0.0528  0.0958  0.1009   \n",
      "13   0.0090  0.0062  0.0253  0.0489  0.1197  0.1589  0.1392  0.0987  0.0955   \n",
      "14   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
      "15   0.0298  0.0615  0.0650  0.0921  0.1615  0.2294  0.2176  0.2033  0.1459   \n",
      "16   0.0352  0.0116  0.0191  0.0469  0.0737  0.1185  0.1683  0.1541  0.1466   \n",
      "17   0.0192  0.0607  0.0378  0.0774  0.1388  0.0809  0.0568  0.0219  0.1037   \n",
      "18   0.0270  0.0092  0.0145  0.0278  0.0412  0.0757  0.1026  0.1138  0.0794   \n",
      "19   0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
      "20   0.0473  0.0509  0.0819  0.1252  0.1783  0.3070  0.3008  0.2362  0.3830   \n",
      "21   0.0664  0.0575  0.0842  0.0372  0.0458  0.0771  0.0771  0.1130  0.2353   \n",
      "22   0.0099  0.0484  0.0299  0.0297  0.0652  0.1077  0.2363  0.2385  0.0075   \n",
      "23   0.0115  0.0150  0.0136  0.0076  0.0211  0.1058  0.1023  0.0440  0.0931   \n",
      "24   0.0293  0.0644  0.0390  0.0173  0.0476  0.0816  0.0993  0.0315  0.0736   \n",
      "25   0.0201  0.0026  0.0138  0.0062  0.0133  0.0151  0.0541  0.0210  0.0505   \n",
      "26   0.0151  0.0320  0.0599  0.1050  0.1163  0.1734  0.1679  0.1119  0.0889   \n",
      "27   0.0177  0.0300  0.0288  0.0394  0.0630  0.0526  0.0688  0.0633  0.0624   \n",
      "28   0.0100  0.0275  0.0190  0.0371  0.0416  0.0201  0.0314  0.0651  0.1896   \n",
      "29   0.0189  0.0308  0.0197  0.0622  0.0080  0.0789  0.1440  0.1451  0.1789   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "178  0.0197  0.0394  0.0384  0.0076  0.0251  0.0629  0.0747  0.0578  0.1357   \n",
      "179  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
      "180  0.0310  0.0221  0.0433  0.0191  0.0964  0.1827  0.1106  0.1702  0.2804   \n",
      "181  0.0423  0.0321  0.0709  0.0108  0.1070  0.0973  0.0961  0.1323  0.2462   \n",
      "182  0.0095  0.0308  0.0539  0.0411  0.0613  0.1039  0.1016  0.1394  0.2592   \n",
      "183  0.0096  0.0404  0.0682  0.0688  0.0887  0.0932  0.0955  0.2140  0.2546   \n",
      "184  0.0269  0.0383  0.0505  0.0707  0.1313  0.2103  0.2263  0.2524  0.3595   \n",
      "185  0.0340  0.0625  0.0381  0.0257  0.0441  0.1027  0.1287  0.1850  0.2647   \n",
      "186  0.0209  0.0191  0.0411  0.0321  0.0698  0.1579  0.1438  0.1402  0.3048   \n",
      "187  0.0368  0.0279  0.0103  0.0566  0.0759  0.0679  0.0970  0.1473  0.2164   \n",
      "188  0.0089  0.0274  0.0248  0.0237  0.0224  0.0845  0.1488  0.1224  0.1569   \n",
      "189  0.0158  0.0239  0.0150  0.0494  0.0988  0.1425  0.1463  0.1219  0.1697   \n",
      "190  0.0156  0.0210  0.0282  0.0596  0.0462  0.0779  0.1365  0.0780  0.1038   \n",
      "191  0.0315  0.0252  0.0167  0.0479  0.0902  0.1057  0.1024  0.1209  0.1241   \n",
      "192  0.0056  0.0267  0.0221  0.0561  0.0936  0.1146  0.0706  0.0996  0.1673   \n",
      "193  0.0203  0.0121  0.0380  0.0128  0.0537  0.0874  0.1021  0.0852  0.1136   \n",
      "194  0.0392  0.0108  0.0267  0.0257  0.0410  0.0491  0.1053  0.1690  0.2105   \n",
      "195  0.0129  0.0141  0.0309  0.0375  0.0767  0.0787  0.0662  0.1108  0.1777   \n",
      "196  0.0050  0.0017  0.0270  0.0450  0.0958  0.0830  0.0879  0.1220  0.1977   \n",
      "197  0.0366  0.0421  0.0504  0.0250  0.0596  0.0252  0.0958  0.0991  0.1419   \n",
      "198  0.0238  0.0318  0.0422  0.0399  0.0788  0.0766  0.0881  0.1143  0.1594   \n",
      "199  0.0116  0.0744  0.0367  0.0225  0.0076  0.0545  0.1110  0.1069  0.1708   \n",
      "200  0.0131  0.0387  0.0329  0.0078  0.0721  0.1341  0.1626  0.1902  0.2610   \n",
      "201  0.0335  0.0258  0.0398  0.0570  0.0529  0.1091  0.1709  0.1684  0.1865   \n",
      "202  0.0272  0.0378  0.0488  0.0848  0.1127  0.1103  0.1349  0.2337  0.3113   \n",
      "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
      "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
      "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
      "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
      "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
      "\n",
      "         9  ...      51      52      53      54      55      56      57  \\\n",
      "0    0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1    0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2    0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3    0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4    0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "5    0.3039 ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
      "6    0.3513 ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
      "7    0.2838 ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
      "8    0.1487 ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
      "9    0.0251 ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
      "10   0.0452 ...  0.0062  0.0120  0.0052  0.0056  0.0093  0.0042  0.0003   \n",
      "11   0.0835 ...  0.0133  0.0265  0.0224  0.0074  0.0118  0.0026  0.0092   \n",
      "12   0.1240 ...  0.0176  0.0127  0.0088  0.0098  0.0019  0.0059  0.0058   \n",
      "13   0.1895 ...  0.0059  0.0095  0.0194  0.0080  0.0152  0.0158  0.0053   \n",
      "14   0.2120 ...  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114  0.0196   \n",
      "15   0.0852 ...  0.0031  0.0153  0.0071  0.0212  0.0076  0.0152  0.0049   \n",
      "16   0.2912 ...  0.0346  0.0158  0.0154  0.0109  0.0048  0.0095  0.0015   \n",
      "17   0.1186 ...  0.0331  0.0131  0.0120  0.0108  0.0024  0.0045  0.0037   \n",
      "18   0.1520 ...  0.0084  0.0010  0.0018  0.0068  0.0039  0.0120  0.0132   \n",
      "19   0.5920 ...  0.0092  0.0035  0.0098  0.0121  0.0006  0.0181  0.0094   \n",
      "20   0.3759 ...  0.0193  0.0118  0.0064  0.0042  0.0054  0.0049  0.0082   \n",
      "21   0.1838 ...  0.0141  0.0190  0.0043  0.0036  0.0026  0.0024  0.0162   \n",
      "22   0.1882 ...  0.0173  0.0149  0.0115  0.0202  0.0139  0.0029  0.0160   \n",
      "23   0.0734 ...  0.0091  0.0016  0.0084  0.0064  0.0026  0.0029  0.0037   \n",
      "24   0.0860 ...  0.0035  0.0052  0.0083  0.0078  0.0075  0.0105  0.0160   \n",
      "25   0.1097 ...  0.0108  0.0070  0.0063  0.0030  0.0011  0.0007  0.0024   \n",
      "26   0.1205 ...  0.0061  0.0015  0.0084  0.0128  0.0054  0.0011  0.0019   \n",
      "27   0.0613 ...  0.0102  0.0122  0.0044  0.0075  0.0124  0.0099  0.0057   \n",
      "28   0.2668 ...  0.0088  0.0104  0.0036  0.0088  0.0047  0.0117  0.0020   \n",
      "29   0.2522 ...  0.0038  0.0096  0.0142  0.0190  0.0140  0.0099  0.0092   \n",
      "..      ... ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "178  0.1695 ...  0.0134  0.0097  0.0042  0.0058  0.0072  0.0041  0.0045   \n",
      "179  0.2558 ...  0.0146  0.0040  0.0114  0.0032  0.0062  0.0101  0.0068   \n",
      "180  0.4432 ...  0.0204  0.0059  0.0053  0.0079  0.0037  0.0015  0.0056   \n",
      "181  0.2696 ...  0.0176  0.0035  0.0093  0.0121  0.0075  0.0056  0.0021   \n",
      "182  0.3745 ...  0.0181  0.0019  0.0102  0.0133  0.0040  0.0042  0.0030   \n",
      "183  0.2952 ...  0.0237  0.0078  0.0144  0.0170  0.0012  0.0109  0.0036   \n",
      "184  0.5915 ...  0.0167  0.0199  0.0145  0.0081  0.0045  0.0043  0.0027   \n",
      "185  0.4117 ...  0.0141  0.0019  0.0067  0.0099  0.0042  0.0057  0.0051   \n",
      "186  0.3914 ...  0.0078  0.0201  0.0104  0.0039  0.0031  0.0062  0.0087   \n",
      "187  0.2544 ...  0.0105  0.0024  0.0018  0.0057  0.0092  0.0009  0.0086   \n",
      "188  0.2119 ...  0.0096  0.0103  0.0093  0.0025  0.0044  0.0021  0.0069   \n",
      "189  0.1923 ...  0.0121  0.0108  0.0057  0.0028  0.0079  0.0034  0.0046   \n",
      "190  0.1567 ...  0.0150  0.0060  0.0082  0.0091  0.0038  0.0056  0.0056   \n",
      "191  0.1533 ...  0.0108  0.0062  0.0044  0.0072  0.0007  0.0054  0.0035   \n",
      "192  0.1859 ...  0.0072  0.0055  0.0074  0.0068  0.0084  0.0037  0.0024   \n",
      "193  0.1747 ...  0.0134  0.0094  0.0047  0.0045  0.0042  0.0028  0.0036   \n",
      "194  0.2471 ...  0.0083  0.0080  0.0026  0.0079  0.0042  0.0071  0.0044   \n",
      "195  0.2245 ...  0.0124  0.0093  0.0072  0.0019  0.0027  0.0054  0.0017   \n",
      "196  0.2282 ...  0.0165  0.0056  0.0010  0.0027  0.0062  0.0024  0.0063   \n",
      "197  0.1847 ...  0.0132  0.0027  0.0022  0.0059  0.0016  0.0025  0.0017   \n",
      "198  0.2048 ...  0.0096  0.0071  0.0084  0.0038  0.0026  0.0028  0.0013   \n",
      "199  0.2271 ...  0.0141  0.0103  0.0100  0.0034  0.0026  0.0037  0.0044   \n",
      "200  0.3193 ...  0.0150  0.0076  0.0032  0.0037  0.0071  0.0040  0.0009   \n",
      "201  0.2660 ...  0.0120  0.0039  0.0053  0.0062  0.0046  0.0045  0.0022   \n",
      "202  0.3997 ...  0.0091  0.0045  0.0043  0.0043  0.0098  0.0054  0.0051   \n",
      "203  0.2684 ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
      "204  0.2154 ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
      "205  0.2529 ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
      "206  0.2354 ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
      "207  0.2354 ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
      "\n",
      "         58      59  60  \n",
      "0    0.0090  0.0032   R  \n",
      "1    0.0052  0.0044   R  \n",
      "2    0.0095  0.0078   R  \n",
      "3    0.0040  0.0117   R  \n",
      "4    0.0107  0.0094   R  \n",
      "5    0.0051  0.0062   R  \n",
      "6    0.0036  0.0103   R  \n",
      "7    0.0048  0.0053   R  \n",
      "8    0.0059  0.0022   R  \n",
      "9    0.0056  0.0040   R  \n",
      "10   0.0053  0.0036   R  \n",
      "11   0.0009  0.0044   R  \n",
      "12   0.0059  0.0032   R  \n",
      "13   0.0189  0.0102   R  \n",
      "14   0.0147  0.0062   R  \n",
      "15   0.0200  0.0073   R  \n",
      "16   0.0073  0.0067   R  \n",
      "17   0.0112  0.0075   R  \n",
      "18   0.0070  0.0088   R  \n",
      "19   0.0116  0.0063   R  \n",
      "20   0.0028  0.0027   R  \n",
      "21   0.0109  0.0079   R  \n",
      "22   0.0106  0.0134   R  \n",
      "23   0.0070  0.0041   R  \n",
      "24   0.0095  0.0011   R  \n",
      "25   0.0057  0.0044   R  \n",
      "26   0.0023  0.0062   R  \n",
      "27   0.0032  0.0019   R  \n",
      "28   0.0091  0.0058   R  \n",
      "29   0.0052  0.0075   R  \n",
      "..      ...     ...  ..  \n",
      "178  0.0047  0.0054   M  \n",
      "179  0.0053  0.0087   M  \n",
      "180  0.0067  0.0054   M  \n",
      "181  0.0043  0.0017   M  \n",
      "182  0.0031  0.0033   M  \n",
      "183  0.0043  0.0018   M  \n",
      "184  0.0055  0.0057   M  \n",
      "185  0.0033  0.0058   M  \n",
      "186  0.0070  0.0042   M  \n",
      "187  0.0110  0.0052   M  \n",
      "188  0.0060  0.0018   M  \n",
      "189  0.0022  0.0021   M  \n",
      "190  0.0048  0.0024   M  \n",
      "191  0.0001  0.0055   M  \n",
      "192  0.0034  0.0007   M  \n",
      "193  0.0013  0.0016   M  \n",
      "194  0.0022  0.0014   M  \n",
      "195  0.0024  0.0029   M  \n",
      "196  0.0017  0.0028   M  \n",
      "197  0.0027  0.0027   M  \n",
      "198  0.0035  0.0060   M  \n",
      "199  0.0057  0.0035   M  \n",
      "200  0.0015  0.0085   M  \n",
      "201  0.0005  0.0031   M  \n",
      "202  0.0065  0.0103   M  \n",
      "203  0.0193  0.0157   M  \n",
      "204  0.0062  0.0067   M  \n",
      "205  0.0077  0.0031   M  \n",
      "206  0.0036  0.0048   M  \n",
      "207  0.0061  0.0115   M  \n",
      "\n",
      "[208 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "f = 5\n",
    "label_ind=60\n",
    "x = 3\n",
    "print(df[f][x], df[label_ind][x])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:06:45.776850Z",
     "start_time": "2017-10-17T17:06:45.570177Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A dummy version of tree nodes\n",
    "'''\n",
    "class Node:\n",
    "      \n",
    "    def __init__(self, data, rows, features, depth, max_depth):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.data = data\n",
    "        self.rows = rows\n",
    "        self.features = features\n",
    "        self.label_index = 60\n",
    "        self.labels = ['R', 'M']\n",
    "        self.spliting_feature_val = None\n",
    "        self.id = '%030x' % random.randrange(16**30)\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.min_feature = None\n",
    "        self.min_break_point = None\n",
    "        self.min_gini = None\n",
    "\n",
    "    \n",
    "    def calc_shannon_entropy(self):\n",
    "        raw_val = 0\n",
    "        for label in self.labels:\n",
    "            members = self.data.loc[self.data[self.label_index] == label]\n",
    "            if len(members) <= 0: continue\n",
    "            filtered = [x for x in members.index.values if x in self.rows]\n",
    "            intermediate = len(filtered)/len(self.rows)\n",
    "            raw_val += -intermediate*np.log2(intermediate)\n",
    "        return raw_val\n",
    "    \n",
    "    def calc_gini_index(self):\n",
    "        raw_val = 1\n",
    "        members = [self.data[self.label_index][x] for x in self.rows]\n",
    "        for label in self.labels:\n",
    "#             members = self.data.loc[self.data[self.label_index] == label]\n",
    "            #maybe do as a for loop?\n",
    "            filtered = [x for x in members if x == label]\n",
    "#             filtered = members\n",
    "            raw_val -= (len(filtered)/len(self.rows))**2\n",
    "        return raw_val\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    calculate info gain from gini/entropy\n",
    "    '''\n",
    "    def cal_info_gain():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def find_break_points(self, df, feature):\n",
    "        breaks = []\n",
    "        for i in range(len(df)-1):\n",
    "            row = df[i:i+1]\n",
    "            next_row = df[i+1:i+2]\n",
    "#             print(row[self.label_index])\n",
    "            if row[self.label_index].values[0] != next_row[self.label_index].values[0]:\n",
    "                breaks.append(next_row[feature].values[0]) #float precision issue, care\n",
    "        return breaks\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    Choose the best feature to split at this point\n",
    "    i.e. low gini/entropy, high infoGain\n",
    "    '''\n",
    "    \n",
    "    def split(self):\n",
    "        #are we a leaf node?\n",
    "        if len(self.rows) == 0:\n",
    "            raise ValueError('The node has no document feed, no more splitting')\n",
    "        elif self.calc_gini_index() == 0:\n",
    "            raise ValueError('The node is pure, no more splitting')\n",
    "        elif self.depth == self.max_depth:\n",
    "            raise ValueError('The node has reached max recursion depth, no more splitting')\n",
    "        elif len(self.features) == 0:\n",
    "            raise ValueError('There are no more features to split on.')\n",
    "            \n",
    "        #we are not a leaf node.\n",
    "        min_gini, min_feature, min_break_point, new_left, new_right = 2, -999, -999, None, None\n",
    "        bp_len_sum = 0\n",
    "        for feature in self.features:\n",
    "#             print('parsing')\n",
    "            to_parse = [(self.data[feature][x],self.data[self.label_index][x]) for x in self.rows]\n",
    "            to_parse = pd.DataFrame(to_parse, columns=(feature,self.label_index), index=self.rows)\n",
    "#             print(to_parse)\n",
    "            to_parse.sort_values(feature, inplace=True)\n",
    "#             print(to_parse)\n",
    "#             to_parse = self.data[[feature, self.label_index]]\n",
    "#             to_parse = to_parse.loc[to_parse.index.isin (self.rows)]\n",
    "#             to_parse.sort_values(feature, inplace=True)\n",
    "#             print(to_parse)\n",
    "            break_points = self.find_break_points(to_parse, feature)\n",
    "#             print(break_points)\n",
    "            bp_len_sum += len(break_points)\n",
    "            for break_point in break_points:\n",
    "                left = Node(self.data, to_parse.loc[to_parse[feature] < break_point].index.values, [x for x in self.features if x != feature], self.depth+1, self.max_depth)\n",
    "#                 left = Node(to_parse.loc[to_parse[feature] <break_point]\n",
    "                right = Node(self.data, to_parse.loc[to_parse[feature] >= break_point].index.values, [x for x in self.features if x != feature], self.depth+1, self.max_depth)\n",
    "                ## We should ajdust this so it pass self.data and reference of rows and cols\n",
    "#                 print(left.index.values)\n",
    "\n",
    "#                 print(self.calc_gini_index(left))\n",
    "                left_gini = left.calc_gini_index() if len(left.rows) > 0 else 0\n",
    "                right_gini = right.calc_gini_index() if len(right.rows) > 0 else 0\n",
    "                total_gini = (left_gini*len(left.rows) + right_gini*len(right.rows) )/(len(left.rows) + len(right.rows) )\n",
    "#                 min_gini = min(total_gini, min_gini)\n",
    "#                 print(self.id, feature, total_gini)\n",
    "                if total_gini < min_gini:\n",
    "                    min_gini, min_break_point, min_feature, new_left, new_right = total_gini, break_point, feature, left, right\n",
    "        if bp_len_sum == 0:\n",
    "            print(to_parse)\n",
    "            print(self.calc_gini_index())\n",
    "        self.left = new_left\n",
    "        self.right = new_right\n",
    "        self.min_feature, self.min_break_point, self.min_gini = min_feature, min_break_point, min_gini\n",
    "        try:\n",
    "            if self.left is None:\n",
    "                print(self.min_feature,self.min_break_point,self.min_gini)\n",
    "            self.left.split()\n",
    "        except ValueError: # probably need a customized error class\n",
    "            pass\n",
    "        try:\n",
    "            self.right.split()\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    def __str__(self):\n",
    "#         if self.left and self.right:\n",
    "        children = [x.id for x in (self.left, self.right)] if self.left and self.right else []\n",
    "        return \"[{ID}, {Gini}, {Size}, {Feature}, {BP}, {Children}]\".format(ID=self.id, \n",
    "                                                            Gini = self.calc_gini_index(),\n",
    "                                                            Size = len(self.rows),\n",
    "                                                            Feature=self.min_feature, \n",
    "                                                            BP=self.min_break_point,\n",
    "                                                           Children=children)\n",
    "#         else:\n",
    "#             \"[{ID}, (Children=None)]\".format(ID=self.id)\n",
    "    \n",
    "    def get_proportions(self, target_label):\n",
    "        members = [self.data[self.label_index][x] for x in self.rows]\n",
    "        filtered = [x for x in members if x == target_label]\n",
    "#         members = self.data.loc[self.data[self.label_index] == target_label]\n",
    "#         filtered = [x for x in members.index.values if x in self.rows]\n",
    "        raw_val = (len(filtered)/len(self.rows))\n",
    "        return raw_val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T17:07:21.996457Z",
     "start_time": "2017-10-17T17:06:46.020532Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  60\n",
      "200  0.0131  M\n",
      "150  0.0209  M\n",
      "2    0.0262  R\n",
      "5    0.0286  R\n",
      "175  0.0294  M\n",
      "130  0.0443  M\n",
      "1    0.0453  R\n",
      "7    0.0519  R\n",
      "4    0.0762  R\n",
      "[0.026200000000000001, 0.029399999999999999, 0.0453]\n",
      "         1  60\n",
      "175  0.0123  M\n",
      "150  0.0278  M\n",
      "200  0.0387  M\n",
      "130  0.0446  M\n",
      "5    0.0453  R\n",
      "1    0.0523  R\n",
      "7    0.0548  R\n",
      "2    0.0582  R\n",
      "4    0.0666  R\n",
      "[0.0453]\n",
      "         2  60\n",
      "150  0.0115  M\n",
      "175  0.0117  M\n",
      "130  0.0235  M\n",
      "5    0.0277  R\n",
      "200  0.0329  M\n",
      "4    0.0481  R\n",
      "7    0.0842  R\n",
      "1    0.0843  R\n",
      "2    0.1099  R\n",
      "[0.027699999999999999, 0.032899999999999999, 0.048099999999999997]\n",
      "         3  60\n",
      "200  0.0078  M\n",
      "175  0.0113  M\n",
      "5    0.0174  R\n",
      "7    0.0319  R\n",
      "4    0.0394  R\n",
      "150  0.0445  M\n",
      "1    0.0689  R\n",
      "130  0.1008  M\n",
      "2    0.1083  R\n",
      "[0.017399999999999999, 0.044499999999999998, 0.068900000000000003, 0.1008, 0.10829999999999999]\n",
      "         4  60\n",
      "5    0.0384  R\n",
      "150  0.0427  M\n",
      "175  0.0497  M\n",
      "4    0.0590  R\n",
      "200  0.0721  M\n",
      "2    0.0974  R\n",
      "7    0.1158  R\n",
      "1    0.1183  R\n",
      "130  0.2252  M\n",
      "[0.042700000000000002, 0.058999999999999997, 0.072099999999999997, 0.0974, 0.22520000000000001]\n",
      "         5  60\n",
      "4    0.0649  R\n",
      "150  0.0766  M\n",
      "7    0.0922  R\n",
      "5    0.0990  R\n",
      "175  0.0998  M\n",
      "200  0.1341  M\n",
      "2    0.2280  R\n",
      "1    0.2583  R\n",
      "130  0.2611  M\n",
      "[0.076600000000000001, 0.092200000000000004, 0.0998, 0.22800000000000001, 0.2611]\n",
      "         6  60\n",
      "7    0.1027  R\n",
      "5    0.1201  R\n",
      "4    0.1209  R\n",
      "175  0.1326  M\n",
      "150  0.1458  M\n",
      "200  0.1626  M\n",
      "130  0.2061  M\n",
      "1    0.2156  R\n",
      "2    0.2431  R\n",
      "[0.1326, 0.21560000000000001]\n",
      "         7  60\n",
      "7    0.0613  R\n",
      "175  0.1117  M\n",
      "150  0.1430  M\n",
      "130  0.1668  M\n",
      "5    0.1833  R\n",
      "200  0.1902  M\n",
      "4    0.2467  R\n",
      "1    0.3481  R\n",
      "2    0.3771  R\n",
      "[0.11169999999999999, 0.18329999999999999, 0.19020000000000001, 0.2467]\n",
      "         8  60\n",
      "7    0.1465  R\n",
      "130  0.1801  M\n",
      "150  0.1894  M\n",
      "5    0.2105  R\n",
      "200  0.2610  M\n",
      "175  0.2984  M\n",
      "1    0.3337  R\n",
      "4    0.3564  R\n",
      "2    0.5598  R\n",
      "[0.18010000000000001, 0.21049999999999999, 0.26100000000000001, 0.3337]\n",
      "         9  60\n",
      "150  0.1853  M\n",
      "7    0.2838  R\n",
      "1    0.2872  R\n",
      "5    0.3039  R\n",
      "130  0.3083  M\n",
      "200  0.3193  M\n",
      "175  0.3473  M\n",
      "4    0.4459  R\n",
      "2    0.6194  R\n",
      "[0.2838, 0.30830000000000002, 0.44590000000000002]\n",
      "         10 60\n",
      "150  0.1748  M\n",
      "7    0.2802  R\n",
      "5    0.2988  R\n",
      "200  0.3468  M\n",
      "130  0.3794  M\n",
      "4    0.4152  R\n",
      "175  0.4231  M\n",
      "1    0.4918  R\n",
      "2    0.6333  R\n",
      "[0.2802, 0.3468, 0.41520000000000001, 0.42309999999999998, 0.49180000000000001]\n",
      "         11 60\n",
      "150  0.1556  M\n",
      "7    0.3086  R\n",
      "200  0.3738  M\n",
      "4    0.3952  R\n",
      "5    0.4250  R\n",
      "175  0.5044  M\n",
      "130  0.5364  M\n",
      "1    0.6552  R\n",
      "2    0.7060  R\n",
      "[0.30859999999999999, 0.37380000000000002, 0.3952, 0.50439999999999996, 0.6552]\n",
      "         12 60\n",
      "150  0.1476  M\n",
      "7    0.2657  R\n",
      "200  0.3055  M\n",
      "4    0.4256  R\n",
      "175  0.5237  M\n",
      "2    0.5544  R\n",
      "130  0.6173  M\n",
      "5    0.6343  R\n",
      "1    0.6919  R\n",
      "[0.26569999999999999, 0.30549999999999999, 0.42559999999999998, 0.52370000000000005, 0.5544, 0.61729999999999996, 0.63429999999999997]\n",
      "         13 60\n",
      "150  0.1378  M\n",
      "200  0.1926  M\n",
      "7    0.3801  R\n",
      "4    0.4135  R\n",
      "175  0.4398  M\n",
      "2    0.5320  R\n",
      "1    0.7797  R\n",
      "130  0.7842  M\n",
      "5    0.8198  R\n",
      "[0.38009999999999999, 0.43980000000000002, 0.53200000000000003, 0.78420000000000001, 0.81979999999999997]\n",
      "         14 60\n",
      "200  0.1385  M\n",
      "150  0.2584  M\n",
      "175  0.3236  M\n",
      "4    0.4528  R\n",
      "7    0.5626  R\n",
      "2    0.6479  R\n",
      "1    0.7464  R\n",
      "130  0.8392  M\n",
      "5    1.0000  R\n",
      "[0.45279999999999998, 0.83919999999999995, 1.0]\n",
      "         15 60\n",
      "200  0.2122  M\n",
      "175  0.2956  M\n",
      "150  0.3827  M\n",
      "7    0.4376  R\n",
      "4    0.5326  R\n",
      "2    0.6931  R\n",
      "130  0.9016  M\n",
      "1    0.9444  R\n",
      "5    0.9988  R\n",
      "[0.43759999999999999, 0.90159999999999996, 0.94440000000000002]\n",
      "         16 60\n",
      "7    0.2617  R\n",
      "200  0.2758  M\n",
      "175  0.3286  M\n",
      "150  0.4784  M\n",
      "2    0.6759  R\n",
      "4    0.7306  R\n",
      "5    0.9508  R\n",
      "1    1.0000  R\n",
      "130  1.0000  M\n",
      "[0.27579999999999999, 0.67589999999999995, 1.0]\n",
      "         17 60\n",
      "7    0.1199  R\n",
      "175  0.3231  M\n",
      "200  0.4576  M\n",
      "150  0.5360  M\n",
      "4    0.6193  R\n",
      "2    0.7551  R\n",
      "1    0.8874  R\n",
      "130  0.8911  M\n",
      "5    0.9025  R\n",
      "[0.3231, 0.61929999999999996, 0.8911, 0.90249999999999997]\n",
      "         18 60\n",
      "4    0.2032  R\n",
      "175  0.4528  M\n",
      "150  0.6192  M\n",
      "200  0.6487  M\n",
      "7    0.6676  R\n",
      "5    0.7234  R\n",
      "1    0.8024  R\n",
      "130  0.8753  M\n",
      "2    0.8929  R\n",
      "[0.45279999999999998, 0.66759999999999997, 0.87529999999999997, 0.89290000000000003]\n",
      "         19 60\n",
      "4    0.4636  R\n",
      "5    0.5122  R\n",
      "175  0.6339  M\n",
      "200  0.7154  M\n",
      "1    0.7818  R\n",
      "130  0.7886  M\n",
      "150  0.7912  M\n",
      "2    0.8619  R\n",
      "7    0.9402  R\n",
      "[0.63390000000000002, 0.78180000000000005, 0.78859999999999997, 0.8619]\n",
      "         20 60\n",
      "5    0.2074  R\n",
      "4    0.4148  R\n",
      "1    0.5212  R\n",
      "175  0.7044  M\n",
      "130  0.7156  M\n",
      "7    0.7832  R\n",
      "2    0.7974  R\n",
      "200  0.8010  M\n",
      "150  0.9264  M\n",
      "[0.70440000000000003, 0.78320000000000001, 0.80100000000000005]\n",
      "         21 60\n",
      "5    0.3985  R\n",
      "1    0.4052  R\n",
      "4    0.4292  R\n",
      "7    0.5352  R\n",
      "2    0.6737  R\n",
      "130  0.7581  M\n",
      "200  0.7924  M\n",
      "175  0.8314  M\n",
      "150  1.0000  M\n",
      "[0.7581]\n",
      "         22 60\n",
      "1    0.3957  R\n",
      "2    0.4293  R\n",
      "4    0.5730  R\n",
      "5    0.5890  R\n",
      "130  0.6372  M\n",
      "7    0.6809  R\n",
      "175  0.8449  M\n",
      "200  0.8793  M\n",
      "150  0.9080  M\n",
      "[0.63719999999999999, 0.68089999999999995, 0.84489999999999998]\n",
      "         23 60\n",
      "5    0.2872  R\n",
      "130  0.3210  M\n",
      "2    0.3648  R\n",
      "1    0.3914  R\n",
      "4    0.5399  R\n",
      "150  0.7435  M\n",
      "175  0.8512  M\n",
      "7    0.9174  R\n",
      "200  1.0000  M\n",
      "[0.32100000000000001, 0.36480000000000001, 0.74350000000000005, 0.91739999999999999, 1.0]\n",
      "         24 60\n",
      "5    0.2043  R\n",
      "130  0.2076  M\n",
      "4    0.3161  R\n",
      "1    0.3250  R\n",
      "2    0.5331  R\n",
      "150  0.5557  M\n",
      "7    0.7613  R\n",
      "175  0.9138  M\n",
      "200  0.9865  M\n",
      "[0.20760000000000001, 0.31609999999999999, 0.55569999999999997, 0.76129999999999998, 0.91379999999999995]\n",
      "         25 60\n",
      "130  0.2279  M\n",
      "4    0.2285  R\n",
      "2    0.2413  R\n",
      "150  0.3172  M\n",
      "1    0.3200  R\n",
      "5    0.5782  R\n",
      "7    0.8220  R\n",
      "200  0.9474  M\n",
      "175  0.9985  M\n",
      "[0.22850000000000001, 0.31719999999999998, 0.32000000000000001, 0.94740000000000002]\n",
      "         26 60\n",
      "150  0.1295  M\n",
      "1    0.3271  R\n",
      "130  0.3309  M\n",
      "2    0.5070  R\n",
      "5    0.5389  R\n",
      "4    0.6995  R\n",
      "7    0.8872  R\n",
      "200  0.9474  M\n",
      "175  1.0000  M\n",
      "[0.3271, 0.33090000000000003, 0.50700000000000001, 0.94740000000000002]\n",
      "         27 60\n",
      "150  0.0598  M\n",
      "1    0.2767  R\n",
      "130  0.2847  M\n",
      "5    0.3750  R\n",
      "7    0.6091  R\n",
      "175  0.7544  M\n",
      "2    0.8533  R\n",
      "200  0.9315  M\n",
      "4    1.0000  R\n",
      "[0.2767, 0.28470000000000001, 0.375, 0.75439999999999996, 0.85329999999999995, 0.93149999999999999, 1.0]\n",
      "         28 60\n",
      "130  0.1949  M\n",
      "150  0.2722  M\n",
      "7    0.2967  R\n",
      "5    0.3411  R\n",
      "1    0.4423  R\n",
      "175  0.4661  M\n",
      "2    0.6036  R\n",
      "4    0.7262  R\n",
      "200  0.8326  M\n",
      "[0.29670000000000002, 0.46610000000000001, 0.60360000000000003, 0.83260000000000001]\n",
      "         29 60\n",
      "7    0.1103  R\n",
      "130  0.1671  M\n",
      "1    0.2028  R\n",
      "150  0.3616  M\n",
      "175  0.3924  M\n",
      "4    0.4724  R\n",
      "5    0.5067  R\n",
      "200  0.6213  M\n",
      "2    0.8514  R\n",
      "[0.1671, 0.20280000000000001, 0.36159999999999998, 0.47239999999999999, 0.62129999999999996, 0.85140000000000005]\n",
      "         30 60\n",
      "130  0.1025  M\n",
      "7    0.1318  R\n",
      "150  0.3293  M\n",
      "200  0.3772  M\n",
      "1    0.3788  R\n",
      "175  0.3849  M\n",
      "4    0.5103  R\n",
      "5    0.5580  R\n",
      "2    0.8512  R\n",
      "[0.1318, 0.32929999999999998, 0.37880000000000003, 0.38490000000000002, 0.51029999999999998]\n",
      "         31 60\n",
      "7    0.0624  R\n",
      "130  0.1362  M\n",
      "200  0.2822  M\n",
      "1    0.2947  R\n",
      "175  0.4674  M\n",
      "5    0.4778  R\n",
      "150  0.4855  M\n",
      "2    0.5045  R\n",
      "4    0.5459  R\n",
      "[0.13619999999999999, 0.29470000000000002, 0.46739999999999998, 0.4778, 0.48549999999999999, 0.50449999999999995]\n",
      "         32 60\n",
      "7    0.0990  R\n",
      "2    0.1862  R\n",
      "1    0.1984  R\n",
      "200  0.2042  M\n",
      "130  0.2212  M\n",
      "4    0.2881  R\n",
      "5    0.3299  R\n",
      "150  0.3936  M\n",
      "175  0.4245  M\n",
      "[0.20419999999999999, 0.28810000000000002, 0.39360000000000001]\n",
      "         33 60\n",
      "4    0.0981  R\n",
      "130  0.1124  M\n",
      "150  0.1845  M\n",
      "200  0.2190  M\n",
      "5    0.2198  R\n",
      "1    0.2341  R\n",
      "2    0.2709  R\n",
      "175  0.3095  M\n",
      "7    0.4006  R\n",
      "[0.1124, 0.2198, 0.3095, 0.40060000000000001]\n",
      "         34 60\n",
      "150  0.0342  M\n",
      "175  0.0752  M\n",
      "1    0.1306  R\n",
      "5    0.1407  R\n",
      "130  0.1677  M\n",
      "4    0.1951  R\n",
      "200  0.2223  M\n",
      "7    0.3666  R\n",
      "2    0.4232  R\n",
      "[0.13059999999999999, 0.16769999999999999, 0.1951, 0.2223, 0.36659999999999998]\n",
      "         35 60\n",
      "130  0.1039  M\n",
      "7    0.1050  R\n",
      "200  0.1327  M\n",
      "150  0.2489  M\n",
      "5    0.2856  R\n",
      "175  0.2885  M\n",
      "2    0.3043  R\n",
      "4    0.4181  R\n",
      "1    0.4182  R\n",
      "[0.105, 0.13270000000000001, 0.28560000000000002, 0.28849999999999998, 0.30430000000000001]\n",
      "         36 60\n",
      "200  0.0521  M\n",
      "7    0.1915  R\n",
      "130  0.2562  M\n",
      "5    0.3807  R\n",
      "1    0.3835  R\n",
      "150  0.3837  M\n",
      "175  0.4072  M\n",
      "4    0.4604  R\n",
      "2    0.6116  R\n",
      "[0.1915, 0.25619999999999998, 0.38069999999999998, 0.38369999999999999, 0.46039999999999998]\n",
      "         37 60\n",
      "200  0.0618  M\n",
      "1    0.1057  R\n",
      "130  0.2624  M\n",
      "175  0.3170  M\n",
      "4    0.3217  R\n",
      "150  0.3514  M\n",
      "7    0.3930  R\n",
      "5    0.4158  R\n",
      "2    0.6756  R\n",
      "[0.1057, 0.26240000000000002, 0.32169999999999999, 0.35139999999999999, 0.39300000000000002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         38 60\n",
      "200  0.1416  M\n",
      "1    0.1840  R\n",
      "130  0.2236  M\n",
      "150  0.2654  M\n",
      "4    0.2828  R\n",
      "175  0.2863  M\n",
      "5    0.4054  R\n",
      "7    0.4288  R\n",
      "2    0.5375  R\n",
      "[0.184, 0.22359999999999999, 0.2828, 0.2863, 0.40539999999999998]\n",
      "         39 60\n",
      "130  0.1180  M\n",
      "200  0.1460  M\n",
      "150  0.1760  M\n",
      "1    0.1970  R\n",
      "4    0.2430  R\n",
      "7    0.2546  R\n",
      "175  0.2634  M\n",
      "5    0.3296  R\n",
      "2    0.4719  R\n",
      "[0.19700000000000001, 0.26340000000000002, 0.3296]\n",
      "         40 60\n",
      "175  0.0541  M\n",
      "200  0.0846  M\n",
      "130  0.1103  M\n",
      "7    0.1151  R\n",
      "150  0.1599  M\n",
      "1    0.1674  R\n",
      "4    0.1979  R\n",
      "5    0.2707  R\n",
      "2    0.4647  R\n",
      "[0.11509999999999999, 0.15989999999999999, 0.16739999999999999]\n",
      "         41 60\n",
      "1    0.0583  R\n",
      "150  0.0866  M\n",
      "200  0.1055  M\n",
      "175  0.1874  M\n",
      "7    0.2196  R\n",
      "4    0.2444  R\n",
      "2    0.2587  R\n",
      "5    0.2650  R\n",
      "130  0.2831  M\n",
      "[0.086599999999999996, 0.21959999999999999, 0.28310000000000002]\n",
      "         42 60\n",
      "150  0.0590  M\n",
      "5    0.0723  R\n",
      "1    0.1401  R\n",
      "200  0.1639  M\n",
      "4    0.1847  R\n",
      "7    0.1879  R\n",
      "2    0.2129  R\n",
      "130  0.2385  M\n",
      "175  0.3459  M\n",
      "[0.072300000000000003, 0.16389999999999999, 0.1847, 0.23849999999999999]\n",
      "         43 60\n",
      "130  0.0255  M\n",
      "150  0.0813  M\n",
      "4    0.0841  R\n",
      "5    0.1238  R\n",
      "7    0.1437  R\n",
      "1    0.1628  R\n",
      "200  0.1916  M\n",
      "2    0.2222  R\n",
      "175  0.4646  M\n",
      "[0.084099999999999994, 0.19159999999999999, 0.22220000000000001, 0.46460000000000001]\n",
      "         44 60\n",
      "150  0.0492  M\n",
      "1    0.0621  R\n",
      "4    0.0692  R\n",
      "5    0.1192  R\n",
      "130  0.1967  M\n",
      "200  0.2085  M\n",
      "2    0.2111  R\n",
      "7    0.2146  R\n",
      "175  0.4366  M\n",
      "[0.062100000000000002, 0.19670000000000001, 0.21110000000000001, 0.43659999999999999]\n",
      "         45 60\n",
      "2    0.0176  R\n",
      "1    0.0203  R\n",
      "150  0.0417  M\n",
      "4    0.0528  R\n",
      "5    0.1089  R\n",
      "130  0.1483  M\n",
      "200  0.2335  M\n",
      "7    0.2360  R\n",
      "175  0.2581  M\n",
      "[0.041700000000000001, 0.0528, 0.14829999999999999, 0.23599999999999999, 0.2581]\n",
      "         46 60\n",
      "4    0.0357  R\n",
      "130  0.0434  M\n",
      "150  0.0495  M\n",
      "1    0.0530  R\n",
      "5    0.0623  R\n",
      "7    0.1125  R\n",
      "175  0.1319  M\n",
      "2    0.1348  R\n",
      "200  0.1964  M\n",
      "[0.043400000000000001, 0.052999999999999999, 0.13189999999999999, 0.1348, 0.19639999999999999]\n",
      "         47 60\n",
      "4    0.0085  R\n",
      "7    0.0254  R\n",
      "150  0.0367  M\n",
      "5    0.0494  R\n",
      "175  0.0505  M\n",
      "130  0.0627  M\n",
      "1    0.0742  R\n",
      "2    0.0744  R\n",
      "200  0.1300  M\n",
      "[0.036700000000000003, 0.049399999999999999, 0.050500000000000003, 0.074200000000000002, 0.13]\n",
      "         48 60\n",
      "175  0.0112  M\n",
      "150  0.0115  M\n",
      "2    0.0130  R\n",
      "4    0.0230  R\n",
      "5    0.0264  R\n",
      "7    0.0285  R\n",
      "1    0.0409  R\n",
      "130  0.0513  M\n",
      "200  0.0633  M\n",
      "[0.012999999999999999, 0.051299999999999998]\n",
      "         49 60\n",
      "4    0.0046  R\n",
      "175  0.0059  M\n",
      "1    0.0061  R\n",
      "5    0.0081  R\n",
      "2    0.0106  R\n",
      "150  0.0118  M\n",
      "7    0.0178  R\n",
      "200  0.0183  M\n",
      "130  0.0473  M\n",
      "[0.0058999999999999999, 0.0061000000000000004, 0.0118, 0.0178, 0.0183]\n",
      "         50 60\n",
      "2    0.0033  R\n",
      "175  0.0041  M\n",
      "7    0.0052  R\n",
      "5    0.0104  R\n",
      "1    0.0125  R\n",
      "150  0.0133  M\n",
      "200  0.0137  M\n",
      "4    0.0156  R\n",
      "130  0.0248  M\n",
      "[0.0041000000000000003, 0.0051999999999999998, 0.013299999999999999, 0.015599999999999999, 0.024799999999999999]\n",
      "         51 60\n",
      "4    0.0031  R\n",
      "5    0.0045  R\n",
      "175  0.0056  M\n",
      "7    0.0081  R\n",
      "1    0.0084  R\n",
      "150  0.0096  M\n",
      "200  0.0150  M\n",
      "2    0.0232  R\n",
      "130  0.0274  M\n",
      "[0.0055999999999999999, 0.0080999999999999996, 0.0095999999999999992, 0.023199999999999998, 0.027400000000000001]\n",
      "         52 60\n",
      "5    0.0014  R\n",
      "150  0.0014  M\n",
      "4    0.0054  R\n",
      "200  0.0076  M\n",
      "1    0.0089  R\n",
      "175  0.0104  M\n",
      "7    0.0120  R\n",
      "2    0.0166  R\n",
      "130  0.0205  M\n",
      "[0.0014, 0.0054000000000000003, 0.0076, 0.0088999999999999999, 0.0104, 0.012, 0.020500000000000001]\n",
      "         53 60\n",
      "200  0.0032  M\n",
      "5    0.0038  R\n",
      "7    0.0045  R\n",
      "1    0.0048  R\n",
      "150  0.0049  M\n",
      "175  0.0079  M\n",
      "2    0.0095  R\n",
      "4    0.0105  R\n",
      "130  0.0141  M\n",
      "[0.0038, 0.0048999999999999998, 0.0094999999999999998, 0.0141]\n",
      "         54 60\n",
      "5    0.0013  R\n",
      "175  0.0014  M\n",
      "200  0.0037  M\n",
      "150  0.0039  M\n",
      "1    0.0094  R\n",
      "4    0.0110  R\n",
      "7    0.0121  R\n",
      "2    0.0180  R\n",
      "130  0.0185  M\n",
      "[0.0014, 0.0094000000000000004, 0.018499999999999999]\n",
      "         55 60\n",
      "4    0.0015  R\n",
      "150  0.0029  M\n",
      "175  0.0054  M\n",
      "130  0.0055  M\n",
      "200  0.0071  M\n",
      "5    0.0089  R\n",
      "7    0.0097  R\n",
      "1    0.0191  R\n",
      "2    0.0244  R\n",
      "[0.0028999999999999998, 0.0088999999999999999]\n",
      "         56 60\n",
      "175  0.0015  M\n",
      "200  0.0040  M\n",
      "130  0.0045  M\n",
      "5    0.0057  R\n",
      "4    0.0072  R\n",
      "150  0.0078  M\n",
      "7    0.0085  R\n",
      "1    0.0140  R\n",
      "2    0.0316  R\n",
      "[0.0057000000000000002, 0.0077999999999999996, 0.0085000000000000006]\n",
      "         57 60\n",
      "175  0.0006  M\n",
      "200  0.0009  M\n",
      "5    0.0027  R\n",
      "7    0.0047  R\n",
      "150  0.0047  M\n",
      "4    0.0048  R\n",
      "1    0.0049  R\n",
      "130  0.0115  M\n",
      "2    0.0164  R\n",
      "[0.0027000000000000001, 0.0047000000000000002, 0.0047999999999999996, 0.0115, 0.016400000000000001]\n",
      "         58 60\n",
      "200  0.0015  M\n",
      "150  0.0021  M\n",
      "7    0.0048  R\n",
      "5    0.0051  R\n",
      "1    0.0052  R\n",
      "175  0.0081  M\n",
      "2    0.0095  R\n",
      "4    0.0107  R\n",
      "130  0.0152  M\n",
      "[0.0047999999999999996, 0.0080999999999999996, 0.0094999999999999998, 0.0152]\n",
      "         59 60\n",
      "150  0.0011  M\n",
      "175  0.0043  M\n",
      "1    0.0044  R\n",
      "7    0.0053  R\n",
      "5    0.0062  R\n",
      "2    0.0078  R\n",
      "200  0.0085  M\n",
      "4    0.0094  R\n",
      "130  0.0100  M\n",
      "[0.0044000000000000003, 0.0085000000000000006, 0.0094000000000000004, 0.01]\n"
     ]
    }
   ],
   "source": [
    "ls = [x for x in range(60)]\n",
    "dummy = Node(df, [1,2,2,7,4,5,200,150, 175, 175, 130], ls, 0, 2)\n",
    "dummy.split()\n",
    "# print(dummy.left.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2ef62a70265f1d9997e4d47fca6bb8, 10, 0.1989, ['9c0dd87015a01f9f519a55a2964a6e', '0c2962436230065c9df75a6370f251']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[9c0dd87015a01f9f519a55a2964a6e, 3, 0.0525, ['7d1487741d4ed031b81f842edcca4c', 'cb4473455a49e874e700b7ed1bc9b2']]\n",
      "[0c2962436230065c9df75a6370f251, 15, 0.6699, ['2324225d9adafafa05568774a45ba8', '2f3e71606996cabfaa3bd4485d4848']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[7d1487741d4ed031b81f842edcca4c, (Children=None)]\n",
      "[cb4473455a49e874e700b7ed1bc9b2, (Children=None)]\n",
      "[2324225d9adafafa05568774a45ba8, (Children=None)]\n",
      "[2f3e71606996cabfaa3bd4485d4848, (Children=None)]\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nodes = [dummy]\n",
    "while(len(nodes) > 0):\n",
    "    new_nodes = []\n",
    "    level_str = ''\n",
    "    for node in nodes:\n",
    "        level_str += str(node) + \"\\n\"\n",
    "        if node.left:\n",
    "            new_nodes.append(node.left)\n",
    "        if node.right:\n",
    "            new_nodes.append(node.right)\n",
    "    print(level_str+\"\\n--------------------------------------------------\", end='\\n')\n",
    "    nodes = new_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T03:09:58.069975Z",
     "start_time": "2017-10-15T03:09:58.052936Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A dummy implementation of decision trees\n",
    "'''\n",
    "class Tree:\n",
    "    \n",
    "    '''\n",
    "    params:\n",
    "    train_data - training data to trainthe tree\n",
    "    depth - max recursion depth of the tree\n",
    "    benchmark - benchmark for geni/entropy\n",
    "    '''\n",
    "    def __init__(self, train_data, depth, benchmark, rows, features): #should we include data here\n",
    "        self.depth = depth\n",
    "        self.rows = rows\n",
    "        self.features = features\n",
    "        self.data = train_data\n",
    "        self.benchmark = benchmark\n",
    "        self.head = Node(train_data, rows, features, 0, depth)\n",
    "        \n",
    "    '''\n",
    "    Recursively split until geni/entropy benchmark met or max_depth reached\n",
    "    '''\n",
    "    def fit(self):\n",
    "        #think about behavior of pure nodes more\n",
    "        try:\n",
    "            self.head.split()\n",
    "        except ValueError: #change this to whatever node.split() throws\n",
    "            print('Head is a pure node.')\n",
    "    '''\n",
    "    params: \n",
    "    test_data - test data to run the prediction on\n",
    "    \n",
    "    return: \n",
    "    outputs confidence/probability of each category\n",
    "    '''\n",
    "    def predict(self, test_data):\n",
    "#         assuming input data is a list right now\n",
    "        cur_node = self.head\n",
    "        while (cur_node.left and cur_node.right):\n",
    "            if (test_data[cur_node.min_feature].values[0] < cur_node.min_break_point):\n",
    "                cur_node = cur_node.left\n",
    "            else:\n",
    "                cur_node = cur_node.right\n",
    "        \n",
    "#         here, cur_node should be the leaf\n",
    "        r_confidence = cur_node.get_proportions('R')\n",
    "        m_confidence = cur_node.get_proportions('M')\n",
    "        \n",
    "        return (r_confidence, m_confidence)\n",
    "    \n",
    "    '''\n",
    "    params: \n",
    "    more_data - more training data to update the tree\n",
    "    \n",
    "    return: \n",
    "    Null or we can say something like which nodes are changed\n",
    "    '''\n",
    "    def update(more_data):\n",
    "        pass\n",
    "    \n",
    "    '''\n",
    "    Maybe we can use pickle for this\n",
    "    '''\n",
    "    def store_tree(file_path):\n",
    "        pass\n",
    "    \n",
    "    def load_tree(file_path):\n",
    "        pass\n",
    "    \n",
    "    '''\n",
    "    String representation\n",
    "    '''\n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        string += str(sorted(self.features))\n",
    "        string += '\\n'\n",
    "        nodes = [self.head]\n",
    "        while(len(nodes) > 0):\n",
    "            new_nodes = []\n",
    "            level_str = ''\n",
    "            for node in nodes:\n",
    "                level_str += str(node) + \"\\n\"\n",
    "                if node.left:\n",
    "                    new_nodes.append(node.left)\n",
    "                if node.right:\n",
    "                    new_nodes.append(node.right)\n",
    "            string += level_str+\"\\n--------------------------------------------------\\n\"\n",
    "            nodes = new_nodes\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ls = [x for x in range(60)]\n",
    "# dummy = Node(df, range(df.shape[0]-20), ls, 0, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f02730e10950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "tree.predict(df[200:201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[200:201][60].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(df, tries):\n",
    "    for i in range(tries):\n",
    "        shuffle = df.sample(frac=1)\n",
    "        tree = Tree(df, 3, None, range(shuffle.shape[0]-20), ls)\n",
    "        tree.fit()\n",
    "        score = 0\n",
    "        for i in range(188, 208):\n",
    "            actual = shuffle[i:i+1][60].values[0]\n",
    "            p = tree.predict(shuffle[i:i+1])\n",
    "            if p[0] > p[1]:\n",
    "        #         print('R/{}'.format(actual))\n",
    "                if 'R' == actual: \n",
    "                    score+=1\n",
    "            else:\n",
    "        #         print('M/{}'.format(actual))\n",
    "                if 'M' == actual: \n",
    "                    score+=1\n",
    "        print(score/(208-188))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "0.95\n",
      "0.95\n",
      "0.95\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "cross_val(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlreadyFitException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T03:09:58.617626Z",
     "start_time": "2017-10-15T03:09:58.578957Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Dummy Version of Random Forest\n",
    "'''\n",
    "class RNF: \n",
    "    '''\n",
    "    params:\n",
    "    train_data - training data to trainthe tree\n",
    "    n_trees - number of trees to setup\n",
    "    tree_depth - max recursive\n",
    "    random_seed - seed for random gen\n",
    "    n_max_features - max num of features to pass to each tree\n",
    "    n_max_input - max num of input to pass to each tree\n",
    "    '''\n",
    "    def __init__(self, train_data, n_trees, tree_depth, random_seed, n_max_features, n_max_input):\n",
    "        self.trees = []\n",
    "        self.train_data = train_data\n",
    "        self.n_trees = n_trees\n",
    "        self.tree_depth = tree_depth\n",
    "        self.n_max_features = n_max_features\n",
    "        self.n_max_input = n_max_input\n",
    "#         self.features = [()] #list of tuples like (tree, emails, features)\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "        np.random.seed(random_seed)\n",
    "        pass\n",
    "    \n",
    "    '''\n",
    "    Randomly select features and emails from the train_data \n",
    "    '''\n",
    "    def random_select(self, train_data):\n",
    "        selected_rows = np.random.choice(self.train_data.shape[0], self.n_max_input)\n",
    "        selected_features = np.random.choice(self.train_data.shape[1] - 1, self.n_max_features, replace=False)\n",
    "        return (selected_rows, selected_features)\n",
    "        \n",
    "    '''\n",
    "    pass randomly selected emails and features to each tree\n",
    "    '''\n",
    "    def fit(self):\n",
    "        if len(self.trees) != 0:\n",
    "            raise AlreadyFitException('This forest has already been fit to the data')\n",
    "        for i in range(self.n_trees):\n",
    "            selected = self.random_select(self.train_data)\n",
    "#             self, train_data, depth, benchmark, rows, features\n",
    "            self.trees.append(Tree(self.train_data, self.tree_depth, 0, selected[0], selected[1]))\n",
    "        for tree in self.trees:\n",
    "            tree.fit()\n",
    "    \n",
    "    '''\n",
    "    calculate a proba from output of each tree's prediction\n",
    "    should ouput two arrays: probas and classfication\n",
    "    '''\n",
    "    def some_majority_count_metric(self, scores):\n",
    "        return np.mean(scores, axis=0)\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        scores = [tree.predict(test_data) for tree in self.trees]\n",
    "        probas = self.some_majority_count_metric(scores)\n",
    "        classes = 'R' if probas[0] > probas[1] else 'M'\n",
    "        return self.some_majority_count_metric(scores), classes\n",
    "    \n",
    "    '''\n",
    "    params: \n",
    "    more_data - more training data to update the forest\n",
    "    \n",
    "    return: \n",
    "    Null or we can say something like which trees are changed\n",
    "    '''\n",
    "    def update(more_data):\n",
    "        pass\n",
    "    \n",
    "    '''\n",
    "    Maybe we can use pickle for this\n",
    "    '''\n",
    "    def store_rnf(file_path):\n",
    "        pass\n",
    "    \n",
    "    def load_rnf(file_path):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = RNF(df[:188], 2, 3, 42, 40, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 16, 18, 19, 21, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59]\n",
      "[477183392456de3eb13b9046685257, 0.4921875, 80, 49, 0.0183, ['ba26a744ed4fd51c2c8fb14de5f2f7', '00463e0a77b5cc2e8746510c2ca7fa']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[ba26a744ed4fd51c2c8fb14de5f2f7, 0.314098750743605, 41, 18, 0.969, ['983c2e15e9bee44e1439774d126ab1', 'ec1c6da0d980baed57a5c89110f698']]\n",
      "[00463e0a77b5cc2e8746510c2ca7fa, 0.4260355029585799, 39, 3, 0.0226, ['68c68e3d231e3b4a97a245da5bf081', '637f145ae57068d2ed9291c3da1521']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[983c2e15e9bee44e1439774d126ab1, 0.2285318559556786, 38, 54, 0.0036, ['c6601d0aaa3c511cd97b172f51270f', '98e361bf4d493dbc57003e91f91586']]\n",
      "[ec1c6da0d980baed57a5c89110f698, 0.0, 3, None, None, []]\n",
      "[68c68e3d231e3b4a97a245da5bf081, 0.0, 6, None, None, []]\n",
      "[637f145ae57068d2ed9291c3da1521, 0.2975206611570247, 33, 8, 0.1237, ['d579efd2d3ea0a249690db3521279f', '97dbce6fbfaeeddf552ac3c66b7b69']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[c6601d0aaa3c511cd97b172f51270f, 0.0, 3, None, None, []]\n",
      "[98e361bf4d493dbc57003e91f91586, 0.10775510204081633, 35, None, None, []]\n",
      "[d579efd2d3ea0a249690db3521279f, 0.40816326530612246, 7, None, None, []]\n",
      "[97dbce6fbfaeeddf552ac3c66b7b69, 0.07396449704142016, 26, None, None, []]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "[0, 2, 6, 7, 9, 11, 12, 13, 14, 17, 18, 19, 20, 22, 24, 26, 27, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 56, 57, 58, 59]\n",
      "[2ff8d207a0ca6e0822e8f36c031199, 0.49875, 80, 42, 0.2564, ['9a4fe2a53ea8bcae44582d89b0026b', '89adddbb1280a987e9974d70fd7536']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[9a4fe2a53ea8bcae44582d89b0026b, 0.40018107741059294, 47, 20, 0.6908, ['16ccf3eaee13de09954f3dad714fa3', '4e5ea880346aec11563f5b21056f8c']]\n",
      "[89adddbb1280a987e9974d70fd7536, 0.21303948576675857, 33, 19, 0.2219, ['a6f2b3c573b9015360cf2cb0d734a6', '95d073e46ecf5e9cf425052bb2689b']]\n",
      "\n",
      "--------------------------------------------------\n",
      "[16ccf3eaee13de09954f3dad714fa3, 0.07133058984910852, 27, 35, 0.1725, ['504473471868142dc3369ba28a6fea', '3a53a2a6e4d53ef8bd0f02a090d3f8']]\n",
      "[4e5ea880346aec11563f5b21056f8c, 0.48, 20, 0, 0.027, ['49fb196fbe5698f150200365503df5', 'd9d1cda4eba7530ffc8725d7cc2646']]\n",
      "[a6f2b3c573b9015360cf2cb0d734a6, 0.0, 4, None, None, []]\n",
      "[95d073e46ecf5e9cf425052bb2689b, 0.0, 29, None, None, []]\n",
      "\n",
      "--------------------------------------------------\n",
      "[504473471868142dc3369ba28a6fea, 0.0, 1, None, None, []]\n",
      "[3a53a2a6e4d53ef8bd0f02a090d3f8, 0.0, 26, None, None, []]\n",
      "[49fb196fbe5698f150200365503df5, 0.4444444444444445, 12, None, None, []]\n",
      "[d9d1cda4eba7530ffc8725d7cc2646, 0.0, 8, None, None, []]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tree in a.trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.83333333,  0.16666667]), 'R')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.predict(df[200:201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200    M\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[200:201][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_rnf(df, tries):\n",
    "    for i in range(tries):\n",
    "        shuffle = df.sample(frac=1)\n",
    "        forest = RNF(df[0:188], 50, 4, random.randint(1, 999), 40, 80)\n",
    "        forest.fit()\n",
    "        score = 0\n",
    "        for i in range(188, 208):\n",
    "            actual = shuffle[i:i+1][60].values[0]\n",
    "            p = forest.predict(shuffle[i:i+1])[1]\n",
    "            if p[0] > p[1]:\n",
    "        #         print('R/{}'.format(actual))\n",
    "                if 'R' == actual: \n",
    "                    score+=1\n",
    "            else:\n",
    "        #         print('M/{}'.format(actual))\n",
    "                if 'M' == actual: \n",
    "                    score+=1\n",
    "        print(score/(208-188))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-80ae12dd6c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_rnf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-4893f5f6b0c8>\u001b[0m in \u001b[0;36mcross_val_rnf\u001b[0;34m(df, tries)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#         print('R/{}'.format(actual))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'R'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "cross_val_rnf(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
