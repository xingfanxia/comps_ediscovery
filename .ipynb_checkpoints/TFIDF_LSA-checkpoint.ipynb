{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "stop_Words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "df = pd.read_csv(\"./data/parsed/training.csv\", dtype=str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>...</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Message-Contents</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri, 15 Jun 2001 11:37:53 -0700 (PDT)</td>\n",
       "      <td>david.allan@enron.com</td>\n",
       "      <td>david.allan@enron.com, e..carter@enron.com, el...</td>\n",
       "      <td>pdated: weekly warrior meeting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Allan, David &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;22329315.1075853164077.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Team room - EB2942, NC</td>\n",
       "      <td>3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri, 15 Jun 2001 11:37:53 -0700 (PDT)</td>\n",
       "      <td>david.allan@enron.com</td>\n",
       "      <td>david.allan@enron.com, e..carter@enron.com, el...</td>\n",
       "      <td>pdated: weekly warrior meeting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Allan, David &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;22329315.1075853164077.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Team room - EB2942, NC</td>\n",
       "      <td>3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fri, 15 Jun 2001 11:37:53 -0700 (PDT)</td>\n",
       "      <td>david.allan@enron.com</td>\n",
       "      <td>david.allan@enron.com, e..carter@enron.com, el...</td>\n",
       "      <td>pdated: weekly warrior meeting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Allan, David &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;22329315.1075853164077.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Team room - EB2942, NC</td>\n",
       "      <td>3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon, 6 Aug 2001 10:47:06 -0700 (PDT)</td>\n",
       "      <td>stacey.wales@enron.com</td>\n",
       "      <td>stacey.wales@enron.com, e..carter@enron.com, p...</td>\n",
       "      <td>Canceled: Pulp Origination Strategy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Wales, Stacey &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;19614702.1075853164028.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Dear Team,\\n\\n\\nI would like to brainstorm ide...</td>\n",
       "      <td>3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A</td>\n",
       "      <td>-1</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon, 6 Aug 2001 10:47:06 -0700 (PDT)</td>\n",
       "      <td>stacey.wales@enron.com</td>\n",
       "      <td>stacey.wales@enron.com, e..carter@enron.com, p...</td>\n",
       "      <td>Canceled: Pulp Origination Strategy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Wales, Stacey &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;19614702.1075853164028.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Dear Team,\\n\\n\\nI would like to brainstorm ide...</td>\n",
       "      <td>3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A</td>\n",
       "      <td>-1</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Unnamed: 0.1                                   Date  \\\n",
       "0          0            0  Fri, 15 Jun 2001 11:37:53 -0700 (PDT)   \n",
       "1          1            1  Fri, 15 Jun 2001 11:37:53 -0700 (PDT)   \n",
       "2          2            2  Fri, 15 Jun 2001 11:37:53 -0700 (PDT)   \n",
       "3          3            3   Mon, 6 Aug 2001 10:47:06 -0700 (PDT)   \n",
       "4          4            4   Mon, 6 Aug 2001 10:47:06 -0700 (PDT)   \n",
       "\n",
       "                     From                                                 To  \\\n",
       "0   david.allan@enron.com  david.allan@enron.com, e..carter@enron.com, el...   \n",
       "1   david.allan@enron.com  david.allan@enron.com, e..carter@enron.com, el...   \n",
       "2   david.allan@enron.com  david.allan@enron.com, e..carter@enron.com, el...   \n",
       "3  stacey.wales@enron.com  stacey.wales@enron.com, e..carter@enron.com, p...   \n",
       "4  stacey.wales@enron.com  stacey.wales@enron.com, e..carter@enron.com, p...   \n",
       "\n",
       "                               Subject Mime-Version  \\\n",
       "0       pdated: weekly warrior meeting          1.0   \n",
       "1       pdated: weekly warrior meeting          1.0   \n",
       "2       pdated: weekly warrior meeting          1.0   \n",
       "3  Canceled: Pulp Origination Strategy          1.0   \n",
       "4  Canceled: Pulp Origination Strategy          1.0   \n",
       "\n",
       "                   Content-Type Content-Transfer-Encoding  \\\n",
       "0  text/plain; charset=us-ascii                      7bit   \n",
       "1  text/plain; charset=us-ascii                      7bit   \n",
       "2  text/plain; charset=us-ascii                      7bit   \n",
       "3  text/plain; charset=us-ascii                      7bit   \n",
       "4  text/plain; charset=us-ascii                      7bit   \n",
       "\n",
       "                                              X-From   ...    X-cc X-bcc  \\\n",
       "0  Allan, David </O=ENRON/OU=NA/CN=RECIPIENTS/CN=...   ...     NaN   NaN   \n",
       "1  Allan, David </O=ENRON/OU=NA/CN=RECIPIENTS/CN=...   ...     NaN   NaN   \n",
       "2  Allan, David </O=ENRON/OU=NA/CN=RECIPIENTS/CN=...   ...     NaN   NaN   \n",
       "3  Wales, Stacey </O=ENRON/OU=NA/CN=RECIPIENTS/CN...   ...     NaN   NaN   \n",
       "4  Wales, Stacey </O=ENRON/OU=NA/CN=RECIPIENTS/CN...   ...     NaN   NaN   \n",
       "\n",
       "                              X-Folder     X-Origin  \\\n",
       "0  \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "1  \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "2  \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "3  \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "4  \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "\n",
       "                      X-FileName  \\\n",
       "0  MCAUSHOL (Non-Privileged).pst   \n",
       "1  MCAUSHOL (Non-Privileged).pst   \n",
       "2  MCAUSHOL (Non-Privileged).pst   \n",
       "3  MCAUSHOL (Non-Privileged).pst   \n",
       "4  MCAUSHOL (Non-Privileged).pst   \n",
       "\n",
       "                                      Message-ID  \\\n",
       "0  <22329315.1075853164077.JavaMail.evans@thyme>   \n",
       "1  <22329315.1075853164077.JavaMail.evans@thyme>   \n",
       "2  <22329315.1075853164077.JavaMail.evans@thyme>   \n",
       "3  <19614702.1075853164028.JavaMail.evans@thyme>   \n",
       "4  <19614702.1075853164028.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Message-Contents  \\\n",
       "0                             Team room - EB2942, NC   \n",
       "1                             Team room - EB2942, NC   \n",
       "2                             Team room - EB2942, NC   \n",
       "3  Dear Team,\\n\\n\\nI would like to brainstorm ide...   \n",
       "4  Dear Team,\\n\\n\\nI would like to brainstorm ide...   \n",
       "\n",
       "                                           ID Label Scenario  \n",
       "0  3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA    -1      401  \n",
       "1  3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA    -1      402  \n",
       "2  3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA    -1      403  \n",
       "3  3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A    -1      401  \n",
       "4  3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A    -1      402  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "#df[\"Message-Contents\"].apply(len)\n",
    "#df[\"Message-Contents\"][16]\n",
    "gross_email = df[df[\"Message-Contents\"].str.contains(\"----\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "'''\n",
    "Email filter class that will hold all of our regexes that we can apply to ALL emails. It is helpful \n",
    "to have it as an objectbecause we can just add the regexes as instance variables and then iterate \n",
    "over all of them using <object>.__dict__.items()\n",
    "'''\n",
    "class Email_filter:\n",
    "     def __init__(self):\n",
    "        ##regexes#\n",
    "        self.quoted = re.compile(r\"^>(\\s)*\", re.MULTILINE)\n",
    "        self.original_or_forward = re.compile(r\"(^(\\s)*-*(\\s)*Original Message(\\s)*-.*$)|(^____.*$)\", re.MULTILINE)\n",
    "        self.metadata = re.compile(r\"(^From:.*$)|(^Sent:.*$)|(^To:.*$)|(^Subject:.*$)|(^Cc:.*$)|(^Date:.*$)|(^Encoding:.*$)\", re.MULTILINE)\n",
    "        self.ole_object = re.compile(r\"(<<.*?>>)+\", re.DOTALL|re.MULTILINE)\n",
    "        self.smtp_header = re.compile(r\"^Message-id:.*?X-Mozilla-Status.*?$\", re.DOTALL|re.MULTILINE)\n",
    "        self.received = re.compile(r\"^Received:(.*?)\\([A-Z]{3}\\)\", re.DOTALL|re.MULTILINE)\n",
    "\n",
    "'''\n",
    "Method to actually filter the emails - creates an email filter object and loops through all of the \n",
    "regexes it contains, running each of them on an email. If the email is a reply, it will first \n",
    "cut out all of the replies.\n",
    "'''\n",
    "def filter_email(s):\n",
    "    if type(s) != str:\n",
    "        return(\"\")\n",
    "    e = Email_filter()\n",
    "    ret = s\n",
    "    for variable_name, regex in e.__dict__.items():  \n",
    "        ret = re.sub(regex, \"\", ret)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "'''\n",
    "Method to cut out all of the replies of emails\n",
    "'''\n",
    "def filter_reply(s):\n",
    "    replies = re.compile(r\"(^(\\s)*-*(\\s)*Original Message.*)\", re.MULTILINE|re.DOTALL)\n",
    "    ret = re.sub(replies, \"\", s)\n",
    "    return ret\n",
    "\n",
    "\n",
    "'''\n",
    "metadata parsing\n",
    "'''\n",
    "from datetime import datetime\n",
    "import re\n",
    "def parse_date(d):\n",
    "    d = d.replace(',', '')\n",
    "    redundancy_filter = d.split(' (')\n",
    "    string = redundancy_filter[0]\n",
    "    datetime_object = datetime.strptime(string, '%a %d %b %Y %X %z')\n",
    "    return datetime_object\n",
    "\n",
    "\n",
    "def x_strip(s):\n",
    "    if s != \"\":\n",
    "        array = re.split(r'</O.*?\\>', s)\n",
    "        array = [x.strip() for x in array]\n",
    "        return array\n",
    "    else:\n",
    "        return([])\n",
    "\n",
    "def to_from_strip(s):\n",
    "    if s != \"\":\n",
    "        return s.split(',')\n",
    "    else:\n",
    "        return([])\n",
    "    \n",
    "def parse_metadata(df):\n",
    "    df['Date'] = df['Date'].apply(parse_date)\n",
    "    df['To'] = df['To'].apply(to_from_strip)\n",
    "    df['From'] = df['From'].apply(to_from_strip)\n",
    "    df['X-To'] = df['X-To'].apply(x_strip)\n",
    "    df['X-From'] = df['X-From'].apply(x_strip)\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "def full_filter_email(df):\n",
    "    df = df.replace(np.nan, '', regex=True)\n",
    "    df.loc[df[\"Subject\"].str.lower().str.startswith('re')][\"Message-Contents\"].apply(filter_reply)\n",
    "    df[\"Message-Contents\"] = df[\"Message-Contents\"].apply(filter_email)\n",
    "    df = parse_metadata(df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gross_email_filtered = pd.DataFrame()\n",
    "gross_email_filtered = full_filter_email(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>...</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Message-Contents</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-06-15 11:37:53-07:00</td>\n",
       "      <td>[david.allan@enron.com]</td>\n",
       "      <td>[david.allan@enron.com,  e..carter@enron.com, ...</td>\n",
       "      <td>pdated: weekly warrior meeting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>[Allan, David, ]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;22329315.1075853164077.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Team room - EB2942, NC</td>\n",
       "      <td>3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-06-15 11:37:53-07:00</td>\n",
       "      <td>[david.allan@enron.com]</td>\n",
       "      <td>[david.allan@enron.com,  e..carter@enron.com, ...</td>\n",
       "      <td>pdated: weekly warrior meeting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>[Allan, David, ]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;22329315.1075853164077.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Team room - EB2942, NC</td>\n",
       "      <td>3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2001-06-15 11:37:53-07:00</td>\n",
       "      <td>[david.allan@enron.com]</td>\n",
       "      <td>[david.allan@enron.com,  e..carter@enron.com, ...</td>\n",
       "      <td>pdated: weekly warrior meeting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>[Allan, David, ]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;22329315.1075853164077.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Team room - EB2942, NC</td>\n",
       "      <td>3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-06 10:47:06-07:00</td>\n",
       "      <td>[stacey.wales@enron.com]</td>\n",
       "      <td>[stacey.wales@enron.com,  e..carter@enron.com,...</td>\n",
       "      <td>Canceled: Pulp Origination Strategy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>[Wales, Stacey, ]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;19614702.1075853164028.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Dear Team,\\n\\n\\nI would like to brainstorm ide...</td>\n",
       "      <td>3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A</td>\n",
       "      <td>-1</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-06 10:47:06-07:00</td>\n",
       "      <td>[stacey.wales@enron.com]</td>\n",
       "      <td>[stacey.wales@enron.com,  e..carter@enron.com,...</td>\n",
       "      <td>Canceled: Pulp Origination Strategy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>[Wales, Stacey, ]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\MCAUSHOL (Non-Privileged)\\Calendar</td>\n",
       "      <td>causholli-m</td>\n",
       "      <td>MCAUSHOL (Non-Privileged).pst</td>\n",
       "      <td>&lt;19614702.1075853164028.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Dear Team,\\n\\n\\nI would like to brainstorm ide...</td>\n",
       "      <td>3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A</td>\n",
       "      <td>-1</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Unnamed: 0.1                       Date  \\\n",
       "0          0            0  2001-06-15 11:37:53-07:00   \n",
       "1          1            1  2001-06-15 11:37:53-07:00   \n",
       "2          2            2  2001-06-15 11:37:53-07:00   \n",
       "3          3            3  2001-08-06 10:47:06-07:00   \n",
       "4          4            4  2001-08-06 10:47:06-07:00   \n",
       "\n",
       "                       From  \\\n",
       "0   [david.allan@enron.com]   \n",
       "1   [david.allan@enron.com]   \n",
       "2   [david.allan@enron.com]   \n",
       "3  [stacey.wales@enron.com]   \n",
       "4  [stacey.wales@enron.com]   \n",
       "\n",
       "                                                  To  \\\n",
       "0  [david.allan@enron.com,  e..carter@enron.com, ...   \n",
       "1  [david.allan@enron.com,  e..carter@enron.com, ...   \n",
       "2  [david.allan@enron.com,  e..carter@enron.com, ...   \n",
       "3  [stacey.wales@enron.com,  e..carter@enron.com,...   \n",
       "4  [stacey.wales@enron.com,  e..carter@enron.com,...   \n",
       "\n",
       "                               Subject Mime-Version  \\\n",
       "0       pdated: weekly warrior meeting          1.0   \n",
       "1       pdated: weekly warrior meeting          1.0   \n",
       "2       pdated: weekly warrior meeting          1.0   \n",
       "3  Canceled: Pulp Origination Strategy          1.0   \n",
       "4  Canceled: Pulp Origination Strategy          1.0   \n",
       "\n",
       "                   Content-Type Content-Transfer-Encoding             X-From  \\\n",
       "0  text/plain; charset=us-ascii                      7bit   [Allan, David, ]   \n",
       "1  text/plain; charset=us-ascii                      7bit   [Allan, David, ]   \n",
       "2  text/plain; charset=us-ascii                      7bit   [Allan, David, ]   \n",
       "3  text/plain; charset=us-ascii                      7bit  [Wales, Stacey, ]   \n",
       "4  text/plain; charset=us-ascii                      7bit  [Wales, Stacey, ]   \n",
       "\n",
       "    ...    X-cc X-bcc                             X-Folder     X-Origin  \\\n",
       "0   ...                \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "1   ...                \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "2   ...                \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "3   ...                \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "4   ...                \\MCAUSHOL (Non-Privileged)\\Calendar  causholli-m   \n",
       "\n",
       "                      X-FileName  \\\n",
       "0  MCAUSHOL (Non-Privileged).pst   \n",
       "1  MCAUSHOL (Non-Privileged).pst   \n",
       "2  MCAUSHOL (Non-Privileged).pst   \n",
       "3  MCAUSHOL (Non-Privileged).pst   \n",
       "4  MCAUSHOL (Non-Privileged).pst   \n",
       "\n",
       "                                      Message-ID  \\\n",
       "0  <22329315.1075853164077.JavaMail.evans@thyme>   \n",
       "1  <22329315.1075853164077.JavaMail.evans@thyme>   \n",
       "2  <22329315.1075853164077.JavaMail.evans@thyme>   \n",
       "3  <19614702.1075853164028.JavaMail.evans@thyme>   \n",
       "4  <19614702.1075853164028.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Message-Contents  \\\n",
       "0                             Team room - EB2942, NC   \n",
       "1                             Team room - EB2942, NC   \n",
       "2                             Team room - EB2942, NC   \n",
       "3  Dear Team,\\n\\n\\nI would like to brainstorm ide...   \n",
       "4  Dear Team,\\n\\n\\nI would like to brainstorm ide...   \n",
       "\n",
       "                                           ID Label Scenario  \n",
       "0  3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA    -1      401  \n",
       "1  3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA    -1      402  \n",
       "2  3.438093.NRVQMDFEDQVCPPCQH1LAKFSPGODI4KJHA    -1      403  \n",
       "3  3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A    -1      401  \n",
       "4  3.438120.GTSTTLNTZ2LVIWQFALPJFBLRPP2UC0G4A    -1      402  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_email_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gross_email_filtered.to_pickle('pickled_data_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE: Transfer of Dana Davis\n",
      "Please check with Maria Lebeau who has been coordinating hiring in the GCP group.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I'm seeking some clarification about the possible transfer of Dana Davis into James Scribner's cost center.    It is my understanding that she was to transfer effective 11/1/01?    Was the position by any chance posted?  Do we need to create a position or is it a transfer into an existing position?\n",
      "Thanks for your help, \n",
      "h\n"
     ]
    }
   ],
   "source": [
    "print(gross_email[\"Subject\"][50846])\n",
    "print(filter_email(gross_email[\"Message-Contents\"][50846], is_reply=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check with Maria Lebeau who has been coordinating hiring in the GCP group.\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tMcLoughlin, Hector  \n",
      "Sent:\tFriday, November 02, 2001 2:20 PM\n",
      "To:\tBoals, Adrial; Davis, Dana; Scribner, James; Carrizales, Blanca\n",
      "Cc:\tCampos, Karen E.; Ormston, Kevin; Perkins, Ramona\n",
      "Subject:\tTransfer of Dana Davis\n",
      "\n",
      "I'm seeking some clarification about the possible transfer of Dana Davis into James Scribner's cost center.    It is my understanding that she was to transfer effective 11/1/01?    Was the position by any chance posted?  Do we need to create a position or is it a transfer into an existing position?\n",
      "Thanks for your help, \n",
      "h\n"
     ]
    }
   ],
   "source": [
    "print(gross_email[\"Message-Contents\"][50846])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.37544512748718 s\n",
      "0.040708065032958984 s\n",
      "41.77961587905884 s\n"
     ]
    }
   ],
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "emails = pd.read_pickle(\"data/parsed/pickles/pickled_data_test.pickle\")\n",
    "\n",
    "start_time = time.time()\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_Words, min_df = .0001)\n",
    "vectorized = vectorizer.fit_transform(emails[\"Message-Contents\"])\n",
    "print(time.time() - start_time, 's')\n",
    "start_time1 = time.time()\n",
    "dumb_numbers = [s for s in vectorizer.get_feature_names() if ((\"0\" in s) or (\"1\" in s) or (\"2\" in s) or (\"3\" in s) or (\"4\" in s) or (\"5\" in s) or (\"6\" in s) or (\"7\" in s) or (\"8\" in s) or (\"9\" in s) or (\"_\" in s))]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(dumb_numbers)\n",
    "print(time.time() - start_time1, 's')\n",
    "start_time2 = time.time()\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words, min_df = .0001)\n",
    "vectorized = vectorizer.fit_transform(emails[\"Message-Contents\"])\n",
    "print(time.time() - start_time2, 's')\n",
    "\n",
    "#print(vectorized.shape)\n",
    "#print(vectorized)\n",
    "#print(vectorized.toarray())\n",
    "#print(vectorizer.idf_)\n",
    "#print(vectorizer.get_feature_names()[:20])\n",
    "#\n",
    "#for item in vectorized:\n",
    "#   print(item)\n",
    "#   for j in range(len(vectorizer.get_feature_names())):\n",
    "#       print(vectorizer.get_feature_names()[j], vectorized.toarray()[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349197, 28303)\n",
      "['aa', 'aaa', 'aadvantage', 'aamodt', 'aaron', 'aau', 'ab', 'aba', 'abacustech', 'abag', 'abalone', 'abandon', 'abandoned', 'abandoning', 'abandonment', 'abanet', 'abate', 'abated', 'abb', 'abbanat', 'abbott', 'abbreviated', 'abbreviation', 'abby', 'abc', 'abcnews', 'abdomen', 'abdullah', 'abe', 'abel', 'abernathy', 'abide', 'abigail', 'abilene', 'abilities', 'ability', 'abitibi', 'able', 'abloy', 'abn', 'abnamro', 'abnormal', 'aboard', 'abolish', 'abort', 'aborted', 'abortion', 'abound', 'abq', 'abraham', 'abramo', 'abrams', 'abreast', 'abroad', 'abrogate', 'abrupt', 'abruptly', 'abs', 'absence', 'absences', 'absense', 'absent', 'absmiddle', 'absolute', 'absolutely', 'absorb', 'absorbed', 'absorbing', 'abstract', 'abstracts', 'absurd', 'abt', 'abu', 'abundance', 'abundant', 'abundantly', 'abuse', 'abused', 'abuses', 'abusing', 'abusive', 'abx', 'ac', 'aca', 'academic', 'academically', 'academics', 'academy', 'acc', 'accelerate', 'accelerated', 'accelerating', 'acceleration', 'accent', 'accents', 'accenture', 'accept', 'acceptability', 'acceptable', 'acceptance', 'accepted', 'accepting', 'accepts', 'acces', 'access', 'accessc', 'accessed', 'accessible', 'accessing', 'accessories', 'accessory', 'accident', 'accidental', 'accidentally', 'accidents', 'accommodate', 'accommodated', 'accommodates', 'accommodating', 'accommodation', 'accommodations', 'accomodate', 'accomodating', 'accomodations', 'accompanied', 'accompanies', 'accompany', 'accompanying', 'accomplish', 'accomplished', 'accomplishes', 'accomplishing', 'accomplishment', 'accomplishments', 'accord', 'accordance', 'according', 'accordingly', 'account', 'accountability', 'accountable', 'accountant', 'accountants', 'accounted', 'accounting', 'accounts', 'accredited', 'accretion', 'accretive', 'accross', 'accrual', 'accrue', 'accrued', 'accruing', 'acct', 'acctg', 'accumulate', 'accumulated', 'accumulating', 'accumulation', 'accuracy', 'accurate', 'accurately', 'accured', 'accusation', 'accusations', 'accuse', 'accused', 'accuses', 'accusing', 'accustomed', 'ace', 'aces', 'acess', 'acevedo', 'aceves', 'aches', 'achievable', 'achieve', 'achieved', 'achievement', 'achievements', 'achieves', 'achieving', 'achilles', 'acid', 'ack', 'ackerman', 'acknowledge', 'acknowledged', 'acknowledgement', 'acknowledgements', 'acknowledges', 'acknowledging', 'acknowledgment', 'acl', 'acm', 'acnenergy', 'acomnes', 'acosta', 'acounts', 'acquaintances', 'acquainted', 'acquire', 'acquired', 'acquires', 'acquiring', 'acquisition', 'acquisitions', 'acr', 'acre', 'acreage', 'acres', 'acrobat', 'acronym', 'act', 'acta', 'acted', 'acting', 'action', 'actions', 'activate', 'activated', 'activating', 'activation', 'active', 'actively', 'actives', 'activist', 'activists', 'activities', 'activity', 'acton', 'actor', 'actors', 'actress', 'acts', 'actual', 'actualize', 'actualized', 'actually', 'actuals', 'acumen', 'acura', 'acutally', 'acute', 'acy', 'ad', 'ada', 'adam', 'adamant', 'adamantly', 'adamiak', 'adamik', 'adams', 'adamsbroadwell', 'adamson', 'adapt', 'adapted', 'adapter', 'adapting', 'adarsh', 'adaytum', 'adc', 'adcupkilo', 'adcupklima', 'add', 'added', 'addendum', 'adder', 'addiction', 'adding', 'addition', 'additional', 'additionally', 'additions', 'additive', 'additonal', 'addr', 'address', 'addressed', 'addressee', 'addressees', 'addresses', 'addressing', 'adds', 'addtional', 'adele', 'adelphia', 'aden', 'adept', 'adequacy', 'adequate', 'adequately', 'ader', 'adhere', 'adherence', 'adhering', 'adidas', 'adinfo', 'adios', 'adjacent', 'adjective', 'adjourn', 'adjourned', 'adjournment', 'adjourns', 'adjust', 'adjustable', 'adjusted', 'adjuster', 'adjusting', 'adjustment', 'adjustments', 'adkins', 'adm', 'admin', 'administer', 'administered', 'administering', 'administers', 'administration', 'administrations', 'administrative', 'administratively', 'administrator', 'administrators', 'admins', 'adminstration', 'admire', 'admission', 'admissions', 'admit', 'admits', 'admitted', 'admittedly', 'admitting', 'adnan', 'adobe', 'adopt', 'adopted', 'adopting', 'adoption', 'adoptions', 'adopts', 'adorable', 'adplaw', 'adr', 'adress', 'adrial', 'adrian', 'adriana', 'adriane', 'adrianne', 'adrienne', 'adrs', 'ads', 'adserver', 'adt', 'adult', 'adults', 'adv', 'advance', 'advanced', 'advancement', 'advancements', 'advances', 'advancing', 'advantage', 'advantageous', 'advantages', 'advent', 'adventure', 'adventures', 'adversarial', 'adversaries', 'adverse', 'adversely', 'adversity', 'advertise', 'advertised', 'advertisement', 'advertisements', 'advertiser', 'advertisers', 'advertising', 'advice', 'advisable', 'advise', 'advised', 'adviser', 'advisers', 'advises', 'advising', 'advisor', 'advisories', 'advisors', 'advisory', 'advocacy', 'advocate', 'advocated', 'advocates', 'advocating', 'advocation', 'ae', 'aec', 'aecm', 'aeco', 'aeglobalmarkets', 'aein', 'aeinfw', 'aelaw', 'aep', 'aepesi', 'aepin', 'aera', 'aeraenergy', 'aerial', 'aeros', 'aerospace', 'aes', 'aesc', 'aetna', 'aext', 'af', 'afala', 'afb', 'afc', 'afcc', 'afcesa', 'affair', 'affairs', 'affect', 'affected', 'affecting', 'affection', 'affects', 'affidavit', 'affidavits', 'affilaites', 'affilate', 'affiliate', 'affiliated', 'affiliates', 'affiliation', 'affiliations', 'affirm', 'affirmation', 'affirmative', 'affirmatively', 'affirmed', 'affirms', 'affluent', 'afford', 'affordable', 'afforded', 'afghan', 'afghanistan', 'afghans', 'afl', 'afloat', 'aforementioned', 'afp', 'afpaschke', 'afraid', 'africa', 'african', 'afterall', 'aftermath', 'afternoon', 'afternoons', 'aftershock', 'afterward', 'afudc', 'afx', 'afxnews', 'afxpress', 'ag', 'aga', 'agarwal', 'agatha', 'agave', 'agc', 'age', 'aged', 'agence', 'agencies', 'agency', 'agenda', 'agendas', 'agent', 'agents', 'ages', 'agg', 'aggie', 'aggies', 'aggravated', 'aggravating', 'aggregate', 'aggregated', 'aggregates', 'aggregating', 'aggregation', 'aggregator', 'aggregators', 'aggressive', 'aggressively', 'agilent', 'agilford', 'agility', 'agin', 'aging', 'agip', 'agl', 'aglandenergy', 'aglet', 'aglife', 'agm', 'agmt', 'agnew', 'ago', 'agold', 'agoldberg', 'agonizing', 'agony', 'agr', 'agree', 'agreeable', 'agreed', 'agreeement', 'agreeing', 'agreement', 'agreements', 'agrees', 'agrement', 'agressive', 'agricole', 'agricultural', 'agriculture', 'agrmt', 'agro', 'ags', 'agsk', 'agt', 'agua', 'aguayo', 'aguilar', 'aguirre', 'agustin', 'ah', 'ahc', 'ahead', 'aherrera', 'ahhh', 'ahmad', 'ahman', 'ahmed', 'ahn', 'ahold', 'ahp', 'ai', 'aiaz', 'aid', 'aida', 'aide', 'aided', 'aides', 'aids', 'aig', 'aikman', 'ail', 'ailing', 'aim', 'aimed', 'aimee', 'aimemail', 'aimfunds', 'aiming', 'aims', 'ain', 'ainslie', 'air', 'airam', 'airborne', 'aircraft', 'aired', 'aires', 'airfare', 'airfares', 'airing', 'airline', 'airlines', 'airmail', 'airplane', 'airplanes', 'airport', 'airports', 'airshow', 'airtran', 'airways', 'aisle', 'aj', 'ajaldrich', 'ajchambe', 'ajello', 'ak', 'aka', 'akamai', 'akamaitech', 'akatz', 'akers', 'akili', 'akin', 'akingump', 'akllp', 'akron', 'akurzer', 'al', 'ala', 'alaadin', 'alabama', 'alain', 'alamac', 'alameda', 'alamitos', 'alamo', 'alamodome', 'alan', 'alanb', 'alarcon', 'alarm', 'alarmed', 'alarming', 'alarms', 'alas', 'alaska', 'alaskaair', 'alaskan', 'alatorre', 'alb', 'albania', 'albany', 'albeit', 'albert', 'alberta', 'albertapower', 'alberto', 'albertson', 'albrecht', 'albright', 'album', 'albums', 'albuquerque', 'alcan', 'alcantar', 'alcantara', 'alcatel', 'alchemy', 'alcoa', 'alcohol', 'alcoholic', 'alcosta', 'alden', 'alder', 'alderman', 'aldine', 'aldrich', 'ale', 'alec', 'aleck', 'alejandra', 'alejandro', 'alert', 'alerted', 'alerting', 'alerts', 'alessandro', 'alex', 'alexander', 'alexanderson', 'alexandra', 'alexandre', 'alexandria', 'alexanms', 'alexia', 'alexis', 'alexm', 'alf', 'alfa', 'alfio', 'alfonso', 'alford', 'alfred', 'alfredo', 'algebraic', 'algeria', 'algonquin', 'algorithm', 'alhambra', 'ali', 'alia', 'alias', 'alice', 'alicia', 'alief', 'alien', 'align', 'aligned', 'aligning', 'alignment', 'alike', 'alina', 'alink', 'alippin', 'alisa', 'alisha', 'alison', 'alittle', 'alive', 'alj', 'allan', 'alland', 'allard', 'allario', 'alle', 'allegation', 'allegations', 'allege', 'alleged', 'allegedly', 'alleges', 'allegheny', 'alleghenyenergy', 'allegiance', 'alleging', 'allegretti', 'allegro', 'allen', 'allenergy', 'allenovery', 'allergies', 'allergy', 'alleviate', 'alley', 'alliance', 'alliances', 'alliant', 'allied', 'allies', 'alligator', 'allison', 'allocatable', 'allocate', 'allocated', 'allocates', 'allocating', 'allocation', 'allocations', 'allot', 'allotted', 'allow', 'allowable', 'allowance', 'allowances', 'allowed', 'allowing', 'allows', 'allred', 'alls', 'alltel', 'allwein', 'ally', 'alma', 'almaida', 'almaty', 'almeida', 'almond', 'aloha', 'alon', 'alongside', 'alonso', 'alonzo', 'alos', 'alot', 'aloud', 'alp', 'alpert', 'alpha', 'alphabetical', 'alphanumeric', 'alpine', 'alport', 'alright', 'als', 'alschuler', 'alstom', 'alstott', 'alt', 'alta', 'altadore', 'altagas', 'alter', 'alteration', 'alterations', 'altered', 'altering', 'alternate', 'alternately', 'alternates', 'alternating', 'alternative', 'alternatively', 'alternatives', 'alters', 'alterson', 'althaus', 'altitude', 'alto', 'altogether', 'alton', 'altra', 'altrade', 'alum', 'aluminium', 'aluminum', 'alumni', 'alums', 'alvarado', 'alvarez', 'alvaro', 'alvin', 'alvis', 'alyson', 'alzheimer', 'ama', 'amadeus', 'amalgamated', 'amalgamation', 'amanda', 'amani', 'amarillo', 'amassing', 'amateur', 'amateurs', 'amaze', 'amazed', 'amazes', 'amazing', 'amazingly', 'amazon', 'ambassador', 'amber', 'ambient', 'ambiguities', 'ambiguity', 'ambiguous', 'ambition', 'ambitions', 'ambitious', 'ambler', 'ambrose', 'ambulance', 'amc', 'amd', 'amelia', 'amen', 'amenable', 'amend', 'amended', 'amending', 'amendment', 'amendments', 'amends', 'amenities', 'amerada', 'amereda', 'ameren', 'amerex', 'amerexenergy', 'america', 'american', 'americans', 'americas', 'ameritech', 'ameritrade', 'ames', 'amesty', 'amex', 'amgen', 'ami', 'amicus', 'amid', 'amidst', 'amie', 'amigo', 'amigos', 'amir', 'amirault', 'amit', 'amita', 'amkilpat', 'ammendment', 'ammendments', 'ammonia', 'ammunition', 'amoco', 'amolina', 'amortization', 'amortized', 'amos', 'amosher', 'amounted', 'amounting', 'amounts', 'amp', 'ampaez', 'amparo', 'ample', 'amr', 'amro', 'ams', 'amsterdam', 'amt', 'amused', 'amusement', 'amusing', 'amy', 'amzn', 'ana', 'anadarko', 'anaheim', 'anahuac', 'anal', 'analog', 'analogous', 'analogy', 'analyses', 'analysis', 'analyst', 'analysts', 'analytic', 'analytical', 'analytics', 'analyze', 'analyzed', 'analyzes', 'analyzing', 'anastas', 'anastasia', 'anaya', 'ancestors', 'anchau', 'anchor', 'anchorage', 'ancient', 'ancillaries', 'ancillary', 'anders', 'andersen', 'anderson', 'andre', 'andrea', 'andreas', 'andrew', 'andrews', 'andrzej', 'andy', 'andybrwn', 'anecdotal', 'aneel', 'aneela', 'anew', 'ang', 'angel', 'angela', 'angeles', 'angelica', 'angelides', 'angelina', 'angeline', 'angelo', 'angelos', 'angels', 'anger', 'angered', 'angie', 'angle', 'angles', 'anglo', 'angnewspapers', 'angola', 'angry', 'angst', 'angts', 'angus', 'anil', 'animal', 'animals', 'animated', 'animation']\n"
     ]
    }
   ],
   "source": [
    "print(vectorized.shape)\n",
    "print(vectorizer.get_feature_names()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA\n",
    "We take the tf-idf matrix and run TruncatedSVD on it with whatever number of dimensions we want to reduce it to. The issue is I don't believe I can pull the categories. I can pull the highest ranking words from each category, but there is no storage of the category iteself. Currently a WIP on pulling each category, but for right now I'm doing the dot product so I can map term to term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.12103525e+00   3.61509066e+00  -2.33146511e-01 ...,  -5.29702190e-04\n",
      "   -1.67906652e-03   6.70518892e-04]\n",
      " [  6.29932816e-02  -3.19861834e-02   2.60552182e-02 ...,   2.42535390e-03\n",
      "   -8.38848981e-03   7.35732443e-04]\n",
      " [  5.12047618e-04  -2.54518820e-04   2.72452806e-03 ...,  -1.23300382e-04\n",
      "    1.13562405e-04  -6.30741958e-05]\n",
      " ..., \n",
      " [  2.74962044e-02  -1.76636630e-02  -1.40860377e-02 ...,  -7.91970362e-03\n",
      "    6.32496853e-03  -1.19838711e-03]\n",
      " [  2.18556766e-02  -5.67358824e-03  -1.02971139e-02 ...,   4.79882970e-03\n",
      "   -3.49597633e-03  -4.91326766e-03]\n",
      " [  2.86396843e-03  -1.19305797e-03   8.61488392e-03 ...,   1.06139196e-04\n",
      "   -1.28891769e-05  -1.87767834e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Implemented without stemming to better work with current tf-idf code and the nasty documents\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100, algorithm='randomized')\n",
    "lsa = svd.fit_transform(vectorized.T)\n",
    "documentLSA = svd.fit_transform(vectorized)\n",
    "\n",
    "print(lsa)\n",
    "\n",
    "def get_closest(term, vectorizer ,model):\n",
    " \n",
    "    index = vectorizer.vocabulary_[term]\n",
    "\n",
    "    model = np.dot(model, model.T)\n",
    "    search_space = np.concatenate( (model[index][:index] , model[index][(index+1):]) )  \n",
    "    out = np.argmax(search_space)\n",
    "    if out<index:\n",
    "        return vectorizer.get_feature_names()[out]\n",
    "    else:\n",
    "        return vectorizer.get_feature_names()[(out+1)]\n",
    "    \n",
    "def get_k_closest(k,term,vectorizer,model):\n",
    "    index = vectorizer.vocabulary_[term]\n",
    "    print(\"index: \", index)\n",
    "\n",
    "    # This is one approach where we take the dot product\n",
    "    # This results in a mapping of terms to terms based on similarity to each other\n",
    "    model = np.dot(model,model.T)\n",
    "    print(model.shape)\n",
    "\n",
    "    closest_terms = {}\n",
    "    print(len(model))\n",
    "    for i in range(len(model)):\n",
    "        closest_terms[vectorizer.get_feature_names()[i]] = model[index][i]\n",
    "    #print(closest_terms)\n",
    "    sorted_list = sorted(closest_terms , key = lambda l : closest_terms[l])\n",
    "    return sorted_list[::-1][0:k]\n",
    "\n",
    "# WIP\n",
    "def get_topics(transformer, model): \n",
    "    model = np.dot(model,model.T)\n",
    "    \n",
    "    closest_terms = {}\n",
    "    for i in range(len(model)):\n",
    "        for i in range(len(model)):\n",
    "            closest_terms[vectorizer.get_feature_names()[i]] = model[index][i]\n",
    "            \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlate\n",
      "index:  4034\n",
      "(4590, 4590)\n",
      "4590\n",
      "['correlate', 'stock', 'tough', 'nbskp', 'dividend']\n"
     ]
    }
   ],
   "source": [
    "print(get_closest(\"stock\", vectorizer, lsa))\n",
    "print(get_k_closest(5, \"stock\", vectorizer, lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(get_closest('DOCUMENT NUMBER', vectorizer, documentLSA))\n",
    "# Replace DOCUMENT NUMBER with a document that you want to find similar for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WIP\n",
    "print(get_topics(vectorizer, lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
